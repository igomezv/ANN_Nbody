{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjRiLscngc1g"
   },
   "source": [
    "# Import initial utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "id": "7yqaJGM6gc12",
    "outputId": "de2a0178-ce75-45a3-e9de-1697e9ea7985"
   },
   "outputs": [],
   "source": [
    "from timeit import timeit\n",
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#preprocesing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "#metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.metrics import average_precision_score\n",
    "#algorithms\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workdirectory = '/home/jazhiel/ML_Notebooks/Cosmology_ML/'\n",
    "workdirectory = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method for confusion matrix plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "    \n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xwgsSp6gc19"
   },
   "source": [
    "# Import GADGET DS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "j1rlRgXzgc1_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.00e+00  2.72e+13  1.14e+13 ... -1.00e+00 -1.00e+00 -1.00e+00]\n",
      "289964\n"
     ]
    }
   ],
   "source": [
    "data_dict = np.load(workdirectory + 'OUTFILE1M.npz') \n",
    "test_flags  = data_dict['test_flags']\n",
    "test_hosts  = data_dict['test_hosts']\n",
    "test_mass   = data_dict['test_mass']\n",
    "test_labels = data_dict['test_labels']\n",
    "test_input  = data_dict['test_input']\n",
    "#test_snid   = dict_data['test_snid']\n",
    "#test_labels = dict_data['test_labels']\n",
    "print(test_mass)\n",
    "print(np.sum(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBxm-BXsgc2E"
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Q-xgFhm6gc2G"
   },
   "outputs": [],
   "source": [
    "dr1 = pd.DataFrame(test_input[0], columns = ['dr1'])\n",
    "dr2 = pd.DataFrame(test_input[1], columns = ['dr2'])\n",
    "dr3 = pd.DataFrame(test_input[2], columns = ['dr3'])\n",
    "dr4 = pd.DataFrame(test_input[3], columns = ['dr4'])\n",
    "dr5 = pd.DataFrame(test_input[4], columns = ['dr5'])\n",
    "dr6 = pd.DataFrame(test_input[5], columns = ['dr6'])\n",
    "dr7 = pd.DataFrame(test_input[6], columns = ['dr7'])\n",
    "dr8 = pd.DataFrame(test_input[7], columns = ['dr8'])\n",
    "dr9 = pd.DataFrame(test_input[8], columns = ['dr9'])\n",
    "dr10 = pd.DataFrame(test_input[9], columns = ['dr10'])\n",
    "#mass = pd.DataFrame(test_mass, columns = ['Halo_Mass'])\n",
    "lbl = pd.DataFrame(test_labels, columns =['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fX9pUiRgc2K"
   },
   "source": [
    "# Select all features and create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "aQqcmO63gc2O"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dr1</th>\n",
       "      <th>dr2</th>\n",
       "      <th>dr3</th>\n",
       "      <th>dr4</th>\n",
       "      <th>dr5</th>\n",
       "      <th>dr6</th>\n",
       "      <th>dr7</th>\n",
       "      <th>dr8</th>\n",
       "      <th>dr9</th>\n",
       "      <th>dr10</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.034862</td>\n",
       "      <td>0.031188</td>\n",
       "      <td>0.029510</td>\n",
       "      <td>0.023249</td>\n",
       "      <td>0.019781</td>\n",
       "      <td>0.015974</td>\n",
       "      <td>0.012721</td>\n",
       "      <td>0.009786</td>\n",
       "      <td>0.007440</td>\n",
       "      <td>0.289964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.227756</td>\n",
       "      <td>0.189632</td>\n",
       "      <td>0.172109</td>\n",
       "      <td>0.165140</td>\n",
       "      <td>0.141545</td>\n",
       "      <td>0.128470</td>\n",
       "      <td>0.113819</td>\n",
       "      <td>0.100527</td>\n",
       "      <td>0.087283</td>\n",
       "      <td>0.074727</td>\n",
       "      <td>0.453746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.595585</td>\n",
       "      <td>-0.549892</td>\n",
       "      <td>-0.513209</td>\n",
       "      <td>-0.493975</td>\n",
       "      <td>-0.424237</td>\n",
       "      <td>-0.388504</td>\n",
       "      <td>-0.333991</td>\n",
       "      <td>-0.275244</td>\n",
       "      <td>-0.223792</td>\n",
       "      <td>-0.192789</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.121499</td>\n",
       "      <td>-0.100307</td>\n",
       "      <td>-0.091526</td>\n",
       "      <td>-0.088415</td>\n",
       "      <td>-0.078871</td>\n",
       "      <td>-0.073475</td>\n",
       "      <td>-0.066620</td>\n",
       "      <td>-0.059508</td>\n",
       "      <td>-0.052420</td>\n",
       "      <td>-0.045206</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.013326</td>\n",
       "      <td>0.016408</td>\n",
       "      <td>0.016513</td>\n",
       "      <td>0.016246</td>\n",
       "      <td>0.014070</td>\n",
       "      <td>0.012956</td>\n",
       "      <td>0.010306</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.006022</td>\n",
       "      <td>0.004334</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.172316</td>\n",
       "      <td>0.150792</td>\n",
       "      <td>0.138625</td>\n",
       "      <td>0.133218</td>\n",
       "      <td>0.114404</td>\n",
       "      <td>0.103466</td>\n",
       "      <td>0.091056</td>\n",
       "      <td>0.079689</td>\n",
       "      <td>0.068860</td>\n",
       "      <td>0.059217</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.196388</td>\n",
       "      <td>1.440001</td>\n",
       "      <td>1.224202</td>\n",
       "      <td>1.120423</td>\n",
       "      <td>0.816344</td>\n",
       "      <td>0.678405</td>\n",
       "      <td>0.520247</td>\n",
       "      <td>0.408871</td>\n",
       "      <td>0.331112</td>\n",
       "      <td>0.266773</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dr1             dr2             dr3             dr4  \\\n",
       "count  1000000.000000  1000000.000000  1000000.000000  1000000.000000   \n",
       "mean         0.040697        0.034862        0.031188        0.029510   \n",
       "std          0.227756        0.189632        0.172109        0.165140   \n",
       "min         -0.595585       -0.549892       -0.513209       -0.493975   \n",
       "25%         -0.121499       -0.100307       -0.091526       -0.088415   \n",
       "50%          0.013326        0.016408        0.016513        0.016246   \n",
       "75%          0.172316        0.150792        0.138625        0.133218   \n",
       "max          2.196388        1.440001        1.224202        1.120423   \n",
       "\n",
       "                  dr5             dr6             dr7             dr8  \\\n",
       "count  1000000.000000  1000000.000000  1000000.000000  1000000.000000   \n",
       "mean         0.023249        0.019781        0.015974        0.012721   \n",
       "std          0.141545        0.128470        0.113819        0.100527   \n",
       "min         -0.424237       -0.388504       -0.333991       -0.275244   \n",
       "25%         -0.078871       -0.073475       -0.066620       -0.059508   \n",
       "50%          0.014070        0.012956        0.010306        0.008146   \n",
       "75%          0.114404        0.103466        0.091056        0.079689   \n",
       "max          0.816344        0.678405        0.520247        0.408871   \n",
       "\n",
       "                  dr9            dr10          labels  \n",
       "count  1000000.000000  1000000.000000  1000000.000000  \n",
       "mean         0.009786        0.007440        0.289964  \n",
       "std          0.087283        0.074727        0.453746  \n",
       "min         -0.223792       -0.192789        0.000000  \n",
       "25%         -0.052420       -0.045206        0.000000  \n",
       "50%          0.006022        0.004334        0.000000  \n",
       "75%          0.068860        0.059217        1.000000  \n",
       "max          0.331112        0.266773        1.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "df = pd.concat([dr1, dr2, dr3, dr4, dr5, dr6, dr7, dr8, dr9, dr10, lbl], axis=1, ignore_index=False, sort=False)\n",
    "df.describe()\n",
    "#df_copy = pd.concat([dr1, dr2, dr3, dr4, dr5, dr6, dr7, dr8, dr9, dr10], axis = 1, ignore_index=False, sort=False)\n",
    "#df_feat = pd.concat([dr1,lbl], axis = 1, ignore_index=False, sort=False)\n",
    "#df_feat\n",
    "#df_feat = pd.DataFrame(dr1)\n",
    "#df_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWj2YAQ5gc2S"
   },
   "source": [
    "# Concatenate and shuffle dataset, then select the training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "CIplgcocgc2V"
   },
   "outputs": [],
   "source": [
    "# df_0 = df.sort_values('labels').head(35604).sample(14300)\n",
    "# df_1 = df.sort_values('labels').tail(14396).sample(14300) \n",
    "# df_1.labels.sum()\n",
    "# df_r = pd.concat([df_0, df_1])\n",
    "\n",
    "df_r = df\n",
    "\n",
    "randomize = np.random.permutation(len(df_r.values))\n",
    "data = df_r.values[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "DDEuR3zHgc2Y"
   },
   "outputs": [],
   "source": [
    "# Define a size for your train set \n",
    "split = 0.8\n",
    "ntrain = int(split * len(data))\n",
    "indx = [ntrain]\n",
    "train_set, test_set = np.split(data, indx)\n",
    "\n",
    "split = 0.5\n",
    "ntrain = int(split * len(test_set))\n",
    "indx = [ntrain]\n",
    "validation_set, test_test = np.split(test_set, indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set[:, :-1]\n",
    "y_train = train_set[:, -1]\n",
    "\n",
    "X_val = validation_set[:, :-1]\n",
    "y_val = validation_set[:, -1]\n",
    "\n",
    "X_test = test_set[:, :-1]\n",
    "y_test = test_set[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "xscaler = StandardScaler()\n",
    "xscaler.fit(X_train)\n",
    "# apply transform\n",
    "X_train_sc = xscaler.transform(X_train)\n",
    "X_val_sc = xscaler.transform(X_val)\n",
    "X_test_sc = xscaler.transform(X_test)\n",
    "\n",
    "xscalerminmax = MinMaxScaler()\n",
    "xscalerminmax.fit(X_train)\n",
    "# apply transform\n",
    "X_train_minmax = xscaler.transform(X_train)\n",
    "X_val_minmax = xscaler.transform(X_val)\n",
    "X_test_minmax = xscaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=['Not in Halo','in Halo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0tObOMmgc2f"
   },
   "source": [
    "# Select data, X for attributes, y for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "UsrD4LyPgc2k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800000, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLIGON_cJH20"
   },
   "source": [
    "## Logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSum9nsbpV5V"
   },
   "outputs": [],
   "source": [
    "Lg = LogisticRegression(random_state=0)\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "# Código a medir\n",
    "for j in range(100):\n",
    "    y_pred = Lg.fit(X_train_sc, y_train).predict(X_test_sc)\n",
    "# -------------\n",
    "\n",
    "fin = time.time()\n",
    "print(\"tiempo de ejecucción \",(fin-inicio)/100, \"s promedio para 100 repeticiones\") # 1.5099220275878906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(timeit('LogisticRegression(random_state=0).fit(X_train, y_trainl).predict(X_test)', number=500))\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize = True,\n",
    "                      title='Logistic Regression')\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "y1=y_pred\n",
    "y_pred=y1\n",
    "r_probs = [0 for _ in range(len(y_test))]\n",
    "rf_probs = Lg.predict_proba(X_test_sc)\n",
    "rf_probs = rf_probs[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "# print('Random (chance) Prediction: AUROC = %.3f' % (r_auc))\n",
    "# print('Random Forest: AUROC = %.3f' % (rf_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "r_auc = roc_auc_score(y_test, r_probs)\n",
    "rf_auc = roc_auc_score(y_test, rf_probs)\n",
    "r_fpr, r_tpr, _ = roc_curve(y_test, r_probs)\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "plt.plot(r_fpr, r_tpr, linestyle='--', label='Random prediction (AUROC = %0.3f)' % r_auc)\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='Logistic regression (AUROC = %0.3f)' % rf_auc)\n",
    "plt.title('Logistic regression')\n",
    "# Axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# Show legend\n",
    "plt.legend(loc=4) # \n",
    "# Show plot\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    Lg, X_test_sc, y_test, name=\"Regression logistica\"\n",
    ")\n",
    "_ = display.ax_.set_title(\"Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision: \",average_precision_score(y_test, y_pred),\"\\n\")\n",
    "print(\"recall: \",recall_score(y_test, y_pred, average='macro'),\"\\n\")\n",
    "print(\"f1_score: \",f1_score(y_test, y_pred, average='macro'),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4_kHLw0-b-e"
   },
   "source": [
    "## Gaussian Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWjh8SL54JFp"
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train_sc, y_train).predict(X_test_sc)\n",
    "\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "# Código a medir\n",
    "for j in range(100):\n",
    "    y_pred = gnb.fit(X_train_sc, y_train).predict(X_test_sc)\n",
    "# -------------\n",
    "\n",
    "fin = time.time()\n",
    "print(\"tiempo de ejecucción \",(fin-inicio)/100, \"s promedio para 100 repeticiones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize = True,\n",
    "                      title='Gaussian NB')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_probs = [0 for _ in range(len(y_test))]\n",
    "rf_probs = gnb.predict_proba(X_test)\n",
    "rf_probs = rf_probs[:, 1]\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "r_auc = roc_auc_score(y_test, r_probs)\n",
    "rf_auc = roc_auc_score(y_test, rf_probs)\n",
    "\n",
    "# print('Random (chance) Prediction: AUROC = %.3f' % (r_auc))\n",
    "# print('Random Forest: AUROC = %.3f' % (rf_auc))\n",
    "\n",
    "r_fpr, r_tpr, _ = roc_curve(y_test, r_probs)\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "plt.plot(r_fpr, r_tpr, linestyle='--', label='Random prediction (AUROC = %0.3f)' % r_auc)\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='Naive Bayes gaussi (AUROC = %0.3f)' % rf_auc)\n",
    "plt.title('ROC Plot, Naive Bayes gauss')\n",
    "# Axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# Show legend\n",
    "plt.legend(loc=4) # \n",
    "# Show plot\n",
    "plt.grid(True)\n",
    "# plt.savefig('/home/jazhiel/Escritorio/Maestria/Machine_Learning/IMG_Tesis/ROC_RF.png')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the precision-recall curves\n",
    "\n",
    "\n",
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    gnb, X_test_sc, y_test, name=\"Naive bayes gaussiano\"\n",
    ")\n",
    "_ = display.ax_.set_title(\"Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Precision: \",average_precision_score(y_test, y_pred),\"\\n\")\n",
    "print(\"recall: \",recall_score(y_test, y_pred, average='macro'),\"\\n\")\n",
    "print(\"f1_score: \",f1_score(y_test, y_pred, average='macro'),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwbLOCsgCHgJ"
   },
   "source": [
    "## Naive bayes bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HlT9LFH7CFda"
   },
   "outputs": [],
   "source": [
    "ber = BernoulliNB()\n",
    "\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "# Código a medir\n",
    "for j in range(100):\n",
    "    y_predber = ber.fit(X_train_sc, y_train).predict(X_test_sc)\n",
    "# -------------\n",
    "\n",
    "fin = time.time()\n",
    "print(\"tiempo de ejecucción \",(fin-inicio)/100, \"s promedio para 100 repeticiones\")\n",
    "\n",
    "\n",
    "\n",
    "y_pred = ber.fit(X_train, y_train).predict(X_test_sc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize = True,\n",
    "                      title='Bernoulli NB')\n",
    "plt.grid(False)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the precision-recall curves\n",
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    ber, X_test_sc, y_test, name=\"Naive bayes bernoulli\"\n",
    ")\n",
    "_ = display.ax_.set_title(\"Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision: \",average_precision_score(y_test, y_pred),\"\\n\")\n",
    "print(\"recall: \",recall_score(y_test, y_pred, average='macro'),\"\\n\")\n",
    "print(\"f1_score: \",f1_score(y_test, y_pred, average='macro'),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yfbiK6rZk-d"
   },
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5brZPPcY_S3z"
   },
   "outputs": [],
   "source": [
    "mult = MultinomialNB()\n",
    "\n",
    "h=0\n",
    "g=0\n",
    "\n",
    "# y_pred = mult.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "# Código a medir\n",
    "for j in range(100):\n",
    "    y_pred = mult.fit(X_train_minmax, y_train).predict(X_test_minmax)\n",
    "# -------------\n",
    "\n",
    "fin = time.time()\n",
    "print(\"tiempo de ejecucción \",(fin-inicio)/100, \"s promedio para 100 repeticiones\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize = True,\n",
    "                      title='Confusion matrix con naive bayes multinomial')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_probs = [0 for _ in range(len(y_test))]\n",
    "rf_probs = mult.predict_proba(X_test)\n",
    "rf_probs = rf_probs[:, 1]\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "r_auc = roc_auc_score(y_test, r_probs)\n",
    "rf_auc = roc_auc_score(y_test, rf_probs)\n",
    "\n",
    "# print('Random (chance) Prediction: AUROC = %.3f' % (r_auc))\n",
    "# print('Random Forest: AUROC = %.3f' % (rf_auc))\n",
    "\n",
    "r_fpr, r_tpr, _ = roc_curve(y_test, r_probs)\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "plt.plot(r_fpr, r_tpr, linestyle='--', label='Random prediction (AUROC = %0.3f)' % r_auc)\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='Naive Bayes Multoinomial (AUROC = %0.3f)' % rf_auc)\n",
    "plt.title('ROC Plot, Naive Bayes Multinomial')\n",
    "# Axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# Show legend\n",
    "plt.legend(loc=4) # \n",
    "# Show plot\n",
    "plt.grid(True)\n",
    "# plt.savefig('/home/jazhiel/Escritorio/Maestria/Machine_Learning/IMG_Tesis/ROC_RF.png')\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the precision-recall curves\n",
    "\n",
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    mult, X_test_minmax, y_test, name=\"Naive bayes multinomial\"\n",
    ")\n",
    "_ = display.ax_.set_title(\"Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision: \",average_precision_score(y_test, y_pred),\"\\n\")\n",
    "print(\"recall: \",recall_score(y_test, y_pred, average='macro'),\"\\n\")\n",
    "print(\"f1_score: \",f1_score(y_test, y_pred, average='macro'),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRxeDp5AZsxr"
   },
   "source": [
    "## Naive bayes complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gnzquYuEbe_7"
   },
   "outputs": [],
   "source": [
    "com = ComplementNB()\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "# Código a medir\n",
    "for j in range(100):\n",
    "    y_pred = com.fit(X_train_sc, y_train).predict(X_test_sc)\n",
    "# -------------\n",
    "\n",
    "fin = time.time()\n",
    "print(\"tiempo de ejecucción \",(fin-inicio)/100, \"s promedio para 100 repeticiones\")\n",
    "\n",
    "\n",
    "ComplementNB()\n",
    "y_pred = com.fit(X_train_sc, y_train).predict(X_test_sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5gNgqpKef5L"
   },
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize = True,\n",
    "                      title='Confusion matrix con Complement NB')\n",
    "plt.grid(False)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "r_probs = [0 for _ in range(len(y_test))]\n",
    "rf_probs = com.predict_proba(X_test_sc)\n",
    "rf_probs = rf_probs[:, 1]\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "r_auc = roc_auc_score(y_test, r_probs)\n",
    "rf_auc = roc_auc_score(y_test, rf_probs)\n",
    "\n",
    "# print('Random (chance) Prediction: AUROC = %.3f' % (r_auc))\n",
    "# print('Random Forest: AUROC = %.3f' % (rf_auc))\n",
    "\n",
    "r_fpr, r_tpr, _ = roc_curve(y_test, r_probs)\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "plt.plot(r_fpr, r_tpr, linestyle='--', label='Random prediction (AUROC = %0.3f)' % r_auc)\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='Naive Bayes Complement (AUROC = %0.3f)' % rf_auc)\n",
    "plt.title('ROC Plot, Naive Bayes Complement')\n",
    "# Axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# Show legend\n",
    "plt.legend(loc=4) # \n",
    "# Show plot\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the precision-recall curves\n",
    "\n",
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    com, X_test_sc, y_test, name=\"Naive bayes complement\"\n",
    ")\n",
    "_ = display.ax_.set_title(\"Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision: \",average_precision_score(y_test, y_pred),\"\\n\")\n",
    "print(\"recall: \",recall_score(y_test, y_pred, average='macro'),\"\\n\")\n",
    "print(\"f1_score: \",f1_score(y_test, y_pred, average='macro'),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAu7Y45tjXLO"
   },
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpOCooPRjlKw"
   },
   "outputs": [],
   "source": [
    "cat = CategoricalNB()\n",
    "inicio = time.time()\n",
    "\n",
    "# Código a medir\n",
    "for j in range(100):\n",
    "    y_pred = cat.fit(X_train_sc, y_trainf).predict(X_test_sc)\n",
    "# -------------\n",
    "\n",
    "fin = time.time()\n",
    "print(\"tiempo de ejecucción \",(fin-inicio)/100, \"s promedio para 100 repeticiones\")\n",
    "\n",
    "y_pred = cat.fit(X_train_sc, y_train).predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize = True,\n",
    "                      title='Confusion matrix con Categorical NB')\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "r_probs = [0 for _ in range(len(y_test))]\n",
    "rf_probs = cat.predict_proba(X_test_sc)\n",
    "rf_probs = rf_probs[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    cat, X_test_sc, y_test, name=\"Naive bayes categorical\"\n",
    ")\n",
    "_ = display.ax_.set_title(\"Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision: \",average_precision_score(y_test, y_pred),\"\\n\")\n",
    "print(\"recall: \",recall_score(y_test, y_pred, average='macro'),\"\\n\")\n",
    "print(\"f1_score: \",f1_score(y_test, y_pred, average='macro'),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(criterion='entropy', max_depth=8, class_weight='balanced')\n",
    "dt = dt.fit(X_train_sc, y_train)\n",
    "#Predict the response for test dataset\n",
    "ypred = dt.predict(X_test_sc)\n",
    "#Model accuracy, how often is the classifier correct\n",
    "#print(cross_val_score(dt1, X1.reshape(-1,1), y, cv=6))\n",
    "print('Training and testing, raw data, all features \\n')\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, ypred))\n",
    "for i, score_tree in enumerate(cross_val_score(dt, X, ylabels, cv = 10)):\n",
    "    print('Decision tree accuracy for the %d score: %0.2f' % (i, score_tree))\n",
    "score_tree=cross_val_score(dt, X ,ylabels, cv=10)\n",
    "#score_tree\n",
    "cv_scores = []\n",
    "print(\"Decision Tree Accuracy: %0.2f (+/- %0.2f)\" % (score_tree.mean(), score_tree.std() * 2 ))\n",
    "cv_score = score_tree.mean()\n",
    "cv_scores.append(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5gmUpHz2gc26"
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "\n",
    "\n",
    "r_probs = [0 for _ in range(len(y_test))]\n",
    "dt_probs = dt.predict_proba(X_test)\n",
    "dt_probs = dt_probs[:, 1]\n",
    "\n",
    "r_auc = roc_auc_score(y_test, r_probs)\n",
    "dt_auc = roc_auc_score(y_test, dt_probs)\n",
    "\n",
    "print('Random (chance) Prediction: AUROC = %.3f' % (r_auc))\n",
    "print('Decision Tree: AUROC = %.3f' % (dt_auc))\n",
    "\n",
    "r_fpr, r_tpr, _ = roc_curve(y_test, r_probs)\n",
    "dt_fpr, dt_tpr, _ = roc_curve(y_test, dt_probs)\n",
    "plt.plot(r_fpr, r_tpr, linestyle='--', label='Random prediction (AUROC = %0.3f)' % r_auc)\n",
    "plt.plot(dt_fpr, dt_tpr, marker='.', label='Decision Tree (AUROC = %0.3f)' % dt_auc)\n",
    "plt.title('ROC Plot: Classification Algorithms')\n",
    "\n",
    "#r_fpr, r_tpr, _ = roc_curve(y_test, r_probs)\n",
    "#rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "#plt.plot(r_fpr, r_tpr, linestyle='--', label='Random prediction (AUROC = %0.3f)' % r_auc)\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='Random Forest (AUROC = %0.3f)' % rf_auc)\n",
    "#plt.title('ROC Plot, $\\delta r$')\n",
    "# Axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# Show legend\n",
    "plt.legend(loc=4) # \n",
    "# Show plot\n",
    "#plt.savefig('/home/jazhiel/Escritorio/Maestria/Machine_Learning/IMG_Tesis/ROC_DT.jpg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBzlPhXFgc28"
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fgW56PrzM6su"
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(probability=True)\n",
    "\n",
    "\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "# Código a medir\n",
    "for j in range(1):\n",
    "    y_pred = clf.fit(X_train_sc, y_train).predict(X_test_sc)\n",
    "# -------------\n",
    "\n",
    "fin = time.time()\n",
    "print(\"tiempo de ejecucción \",(fin-inicio)/1, \"s promedio para 1 repeticiones\") # 1.5099220275878906\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=['Not in Halo','in Halo']\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize = True,\n",
    "                      title='Confusion matrix con Suport vector machine')\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_probs = [0 for _ in range(len(y_test))]\n",
    "rf_probs = clf.predict_proba(X_test_sc)\n",
    "rf_probs = rf_probs[:, 1]\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "r_auc = roc_auc_score(y_test, r_probs)\n",
    "rf_auc = roc_auc_score(y_test, rf_probs)\n",
    "\n",
    "# print('Random (chance) Prediction: AUROC = %.3f' % (r_auc))\n",
    "# print('Random Forest: AUROC = %.3f' % (rf_auc))\n",
    "\n",
    "r_fpr, r_tpr, _ = roc_curve(y_test, r_probs)\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "plt.plot(r_fpr, r_tpr, linestyle='--', label='Random prediction (AUROC = %0.3f)' % r_auc)\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='Suport vector machine (AUROC = %0.3f)' % rf_auc)\n",
    "plt.title('ROC Plot, Suport vector machine')\n",
    "# Axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# Show legend\n",
    "plt.legend(loc=4) # \n",
    "# Show plot\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plot the precision-recall curves\n",
    "# display = PrecisionRecallDisplay.from_estimator(\n",
    "#     clf, X_test, y_test, name=\"support vector machine\"\n",
    "# )\n",
    "# _ = display.ax_.set_title(\"Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision: \",average_precision_score(y_test, y_pred),\"\\n\")\n",
    "print(\"recall: \",recall_score(y_test, y_pred, average='macro'),\"\\n\")\n",
    "print(\"f1_score: \",f1_score(y_test, y_pred, average='macro'),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIcrEl-ugc2t"
   },
   "source": [
    "# ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jYe90zzSgc2u"
   },
   "outputs": [],
   "source": [
    "r_probs = [0 for _ in range(len(y_test))]\n",
    "rf_probs = rf.predict_proba(X_test)\n",
    "rf_probs = rf_probs[:, 1]\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "# plt.figure(figsize=(10,8))\n",
    "\n",
    "r_auc = roc_auc_score(y_test, r_probs)\n",
    "rf_auc = roc_auc_score(y_test, rf_probs)\n",
    "\n",
    "print('Random (chance) Prediction: AUROC = %.3f' % (r_auc))\n",
    "print('Random Forest: AUROC = %.3f' % (rf_auc))\n",
    "\n",
    "r_fpr, r_tpr, _ = roc_curve(y_test, r_probs)\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "plt.plot(r_fpr, r_tpr, linestyle='--', label='Random prediction (AUROC = %0.3f)' % r_auc)\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='Random Forest (AUROC = %0.3f)' % rf_auc)\n",
    "plt.title('ROC Plot, Random Forest')\n",
    "# Axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# Show legend\n",
    "plt.legend(loc=4) # \n",
    "# Show plot\n",
    "plt.grid(True)\n",
    "# plt.savefig('/home/jazhiel/Escritorio/Maestria/Machine_Learning/IMG_Tesis/ROC_RF.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7Al72Qdgc2w"
   },
   "outputs": [],
   "source": [
    "features = ['$\\delta_{r1}$', '$\\delta_{r2}$', '$\\delta_{r3}$', '$\\delta_{r4}$', '$\\delta_{r5}$', '$\\delta_{r6}$', '$\\delta_{r7}$', '$\\delta_{r8}$', '$\\delta_{r9}$', '$\\delta_{r10}$']\n",
    "feature_imp = pd.Series(rf.feature_importances_,index=features)\n",
    "print(feature_imp)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.style.use('ggplot')\n",
    "# Creating a bar plot\n",
    "sns.barplot(x=feature_imp.index, y=feature_imp)\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Features Importance Score')\n",
    "plt.title(\"Relative feature importances, Random Forest\")\n",
    "plt.legend()\n",
    "plt.savefig('/home/jazhiel/Escritorio/Maestria/Machine_Learning/IMG_Tesis/features_RF.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npQI25iSgc2z"
   },
   "source": [
    "# Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z5LEqnYngc20"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Create CV training and test scores for various training set sizes\n",
    "train_sizes, train_scores, test_scores = learning_curve(rf, \n",
    "                                                        X, \n",
    "                                                        ylabels,\n",
    "                                                        # Number of folds in cross-validation\n",
    "                                                        cv=3,\n",
    "                                                        # Evaluation metric\n",
    "                                                        scoring='accuracy',\n",
    "                                                        # Use all computer cores\n",
    "                                                        n_jobs=-1, \n",
    "                                                        # 50 different sizes of the training set\n",
    "                                                        train_sizes=np.linspace(0.01, 1.0, 50))\n",
    "print('---elapsed time = %s seconds ---' % (time.time()- start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iaWcTcv5gc22"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rv0XeAkmgc23"
   },
   "outputs": [],
   "source": [
    "#Create means and standard deviations for train set scores\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Create means and standard deviations of test set scores\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Draw lines\n",
    "plt.plot(train_sizes, train_mean, '--', color='r',  label=\"Training score\")\n",
    "plt.plot(train_sizes, test_mean, color='b', label=\"Cross-validation score\")\n",
    "\n",
    "# Draw bands\n",
    "plt.fill_between(train_sizes,\n",
    "                 train_mean - train_std,\n",
    "                 train_mean + train_std,\n",
    "                 color=\"r\", alpha =0.15)\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                 test_mean - test_std,\n",
    "                 test_mean + test_std,\n",
    "                 color=\"b\", alpha = 0.15)\n",
    "\n",
    "# Create plot\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.title(\"Learning Curve, Random Forest Classifier\") # All Features, ENZO dataset\")\n",
    "plt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fieIEVE0Nd6U"
   },
   "source": [
    "## Codigo curvas roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBaMearxNbl3"
   },
   "outputs": [],
   "source": [
    "# r_probs = [0 for _ in range(len(y_test))]\n",
    "# rf_probs = ber.predict_proba(X_test_sc)\n",
    "# rf_probs = rf_probs[:, 1]\n",
    "\n",
    "# plt.style.use('ggplot')\n",
    "# plt.figure(figsize=(10,8))\n",
    "\n",
    "# rf_probs = rf.predict_proba(X_test_sc)\n",
    "# rf_probs = rf_probs[:, 1]\n",
    "# plt.style.use('ggplot')\n",
    "# # plt.figure(figsize=(10,8))\n",
    "\n",
    "# r_auc = roc_auc_score(y_test, r_probs)\n",
    "# rf_auc = roc_auc_score(y_test, rf_probs)\n",
    "\n",
    "# r_fpr, r_tpr, _ = roc_curve(y_test, r_probs)\n",
    "# rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "# plt.plot(rf_fpr, rf_tpr, marker='.', label='Random Forest (AUROC = %0.3f)' % rf_auc)\n",
    "\n",
    "# plt.legend(loc=4) # \n",
    "# -------------------------------------------------\n",
    "\n",
    "r_probs = [0 for _ in range(len(y_test))]\n",
    "rf_probs = Lg.predict_proba(X_test_sc)\n",
    "rf_probs = rf_probs[:, 1]\n",
    "\n",
    "\n",
    "r_auc = roc_auc_score(y_test, r_probs)\n",
    "rf_auc = roc_auc_score(y_test, rf_probs)\n",
    "\n",
    "r_fpr, r_tpr, _ = roc_curve(y_test, r_probs)\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='Regression logistica (AUROC = %0.3f)' % rf_auc)\n",
    "\n",
    "\n",
    "plt.legend(loc=4) # \n",
    "\n",
    "# ----------------------------------------------\n",
    "\n",
    "\n",
    "rf_probs = gnb.predict_proba(X_test_sc)\n",
    "rf_probs = rf_probs[:, 1]\n",
    "\n",
    "r_auc = roc_auc_score(y_test, r_probs)\n",
    "rf_auc = roc_auc_score(y_test, rf_probs)\n",
    "\n",
    "\n",
    "r_fpr, r_tpr, _ = roc_curve(y_test, r_probs)\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='Naive Bayes gaussi (AUROC = %0.3f)' % rf_auc)\n",
    "\n",
    "# Show legend\n",
    "plt.legend(loc=4) # \n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "rf_probs = clf.predict_proba(X_test)\n",
    "rf_probs = rf_probs[:, 1]\n",
    "\n",
    "\n",
    "r_auc = roc_auc_score(y_test, r_probs)\n",
    "rf_auc = roc_auc_score(y_test, rf_probs)\n",
    "\n",
    "\n",
    "r_fpr, r_tpr, _ = roc_curve(y_test, r_probs)\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='Suport vector machine (AUROC = %0.3f)' % rf_auc)\n",
    "\n",
    "\n",
    "plt.legend(loc=4) # \n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "r_auc = roc_auc_score(y_test, r_probs)\n",
    "rf_auc = roc_auc_score(y_test, rf_probs)\n",
    "\n",
    "r_fpr, r_tpr, _ = roc_curve(y_test, r_probs)\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='Naive Bayes Bernoulli (AUROC = %0.3f)' % rf_auc)\n",
    "plt.title('ROC Plot, Naive Bayes Bernoulli')\n",
    "# Axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# Show legend\n",
    "plt.legend(loc=4) # \n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "# ------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred = mult.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\n",
    "r_probs = [0 for _ in range(len(y_test))]\n",
    "rf_probs = mult.predict_proba(X_test)\n",
    "rf_probs = rf_probs[:, 1]\n",
    "\n",
    "\n",
    "r_auc = roc_auc_score(y_test, r_probs)\n",
    "rf_auc = roc_auc_score(y_test, rf_probs)\n",
    "\n",
    "\n",
    "r_fpr, r_tpr, _ = roc_curve(y_test, r_probs)\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='Naive Bayes Multoinomial (AUROC = %0.3f)' % rf_auc)\n",
    "\n",
    "\n",
    "plt.legend(loc=4) # \n",
    "\n",
    "# --------------------------------------\n",
    "\n",
    "y_pred = com.fit(X_train, y_train).predict(X_test)\n",
    "rf_probs = com.predict_proba(X_test)\n",
    "rf_probs = rf_probs[:, 1]\n",
    "\n",
    "\n",
    "r_auc = roc_auc_score(y_test, r_probs)\n",
    "rf_auc = roc_auc_score(y_test, rf_probs)\n",
    "\n",
    "r_fpr, r_tpr, _ = roc_curve(y_test, r_probs)\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='Naive Bayes Complement (AUROC = %0.3f)' % rf_auc)\n",
    "\n",
    "# Show legend\n",
    "plt.legend(loc=4) # \n",
    "\n",
    "\n",
    "# --------------------------------\n",
    "\n",
    "\n",
    "\n",
    "r_probs = [0 for _ in range(len(y_test))]\n",
    "rf_probs = cat.predict_proba(X_test)\n",
    "rf_probs = rf_probs[:, 1]\n",
    "\n",
    "r_auc = roc_auc_score(y_test, r_probs)\n",
    "rf_auc = roc_auc_score(y_test, rf_probs)\n",
    "\n",
    "r_fpr, r_tpr, _ = roc_curve(y_test, r_probs)\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='Naive Bayes Categorical (AUROC = %0.3f)' % rf_auc)\n",
    "plt.plot(r_fpr, r_tpr, linestyle='--', label='Random prediction (AUROC = %0.3f)' % r_auc)\n",
    "\n",
    "\n",
    "# Show legend\n",
    "plt.legend(loc=4) # \n",
    "\n",
    "# ------------------------------------------\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copia de RF_Particles_z23.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
