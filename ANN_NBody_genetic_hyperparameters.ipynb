{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook implements Deep learning techniques for a particle-in-halo classification framework. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# workdirectory = '/home/jazhiel/ML_Notebooks/Cosmology_ML/'\n",
    "workdirectory = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/isidro/Documents/github/nnogada/\")\n",
    "from nnogada.Nnogada import Nnogada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import our dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.00000000e+00  2.72242898e+13  1.13894322e+13 ... -1.00000000e+00\n",
      " -1.00000000e+00 -1.00000000e+00]\n",
      "289964\n"
     ]
    }
   ],
   "source": [
    "data_dict = np.load(workdirectory+'OUTFILE1M.npz')\n",
    "test_flags  = data_dict['test_flags'] ## not important\n",
    "test_hosts  = data_dict['test_hosts'] ### somewhat relevant\n",
    "test_mass   = data_dict['test_mass'] ## important\n",
    "test_labels = data_dict['test_labels'] ## important\n",
    "test_input  = data_dict['test_input'] ## very important\n",
    "#test_snid   = dict_data['test_snid']\n",
    "#test_labels = dict_data['test_labels']\n",
    "print(test_mass) ## Here I want to check how is the halo mass matrix composed of, the -1 means the halo \n",
    "#is not in our range of 10^12-10^13 M_sun\n",
    "print(np.sum(test_labels)) ## Here I want to check how many label \"1\" do we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### here we create or 10 vector dataset, I wonder if by adding some other information the classification will be better\n",
    "### adding mass is not helpful, the classifier is perfect in that regard\n",
    "dr1 = pd.DataFrame(test_input[0], columns = ['dr1'])\n",
    "dr2 = pd.DataFrame(test_input[1], columns = ['dr2'])\n",
    "dr3 = pd.DataFrame(test_input[2], columns = ['dr3'])\n",
    "dr4 = pd.DataFrame(test_input[3], columns = ['dr4'])\n",
    "dr5 = pd.DataFrame(test_input[4], columns = ['dr5'])\n",
    "dr6 = pd.DataFrame(test_input[5], columns = ['dr6'])\n",
    "dr7 = pd.DataFrame(test_input[6], columns = ['dr7'])\n",
    "dr8 = pd.DataFrame(test_input[7], columns = ['dr8'])\n",
    "dr9 = pd.DataFrame(test_input[8], columns = ['dr9'])\n",
    "dr10 = pd.DataFrame(test_input[9], columns = ['dr10'])\n",
    "#mass = pd.DataFrame(test_mass, columns = ['Halo_Mass'])\n",
    "lbl = pd.DataFrame(test_labels, columns =['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select all features and create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dr1</th>\n",
       "      <th>dr2</th>\n",
       "      <th>dr3</th>\n",
       "      <th>dr4</th>\n",
       "      <th>dr5</th>\n",
       "      <th>dr6</th>\n",
       "      <th>dr7</th>\n",
       "      <th>dr8</th>\n",
       "      <th>dr9</th>\n",
       "      <th>dr10</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.209889</td>\n",
       "      <td>-0.187730</td>\n",
       "      <td>-0.169542</td>\n",
       "      <td>-0.155964</td>\n",
       "      <td>-0.100744</td>\n",
       "      <td>-0.049741</td>\n",
       "      <td>-0.011099</td>\n",
       "      <td>-0.010984</td>\n",
       "      <td>-0.002834</td>\n",
       "      <td>0.024089</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.364046</td>\n",
       "      <td>0.430008</td>\n",
       "      <td>0.453121</td>\n",
       "      <td>0.450021</td>\n",
       "      <td>0.374578</td>\n",
       "      <td>0.309706</td>\n",
       "      <td>0.240559</td>\n",
       "      <td>0.190503</td>\n",
       "      <td>0.174401</td>\n",
       "      <td>0.176335</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.311775</td>\n",
       "      <td>0.254511</td>\n",
       "      <td>0.227109</td>\n",
       "      <td>0.215286</td>\n",
       "      <td>0.148460</td>\n",
       "      <td>0.112097</td>\n",
       "      <td>0.090454</td>\n",
       "      <td>0.058546</td>\n",
       "      <td>0.035873</td>\n",
       "      <td>0.043613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.033877</td>\n",
       "      <td>0.051836</td>\n",
       "      <td>0.065151</td>\n",
       "      <td>0.073930</td>\n",
       "      <td>0.100935</td>\n",
       "      <td>0.100271</td>\n",
       "      <td>0.094132</td>\n",
       "      <td>0.080007</td>\n",
       "      <td>0.059981</td>\n",
       "      <td>0.032160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.355428</td>\n",
       "      <td>-0.330448</td>\n",
       "      <td>-0.306125</td>\n",
       "      <td>-0.291701</td>\n",
       "      <td>-0.253399</td>\n",
       "      <td>-0.215256</td>\n",
       "      <td>-0.163749</td>\n",
       "      <td>-0.124680</td>\n",
       "      <td>-0.080408</td>\n",
       "      <td>-0.051999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0.022223</td>\n",
       "      <td>0.034349</td>\n",
       "      <td>0.046298</td>\n",
       "      <td>0.047812</td>\n",
       "      <td>0.027945</td>\n",
       "      <td>0.018082</td>\n",
       "      <td>0.012005</td>\n",
       "      <td>0.015623</td>\n",
       "      <td>0.028762</td>\n",
       "      <td>0.036779</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>-0.178963</td>\n",
       "      <td>-0.188312</td>\n",
       "      <td>-0.189045</td>\n",
       "      <td>-0.187326</td>\n",
       "      <td>-0.182576</td>\n",
       "      <td>-0.170714</td>\n",
       "      <td>-0.155041</td>\n",
       "      <td>-0.143078</td>\n",
       "      <td>-0.136640</td>\n",
       "      <td>-0.120222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>-0.164632</td>\n",
       "      <td>-0.113120</td>\n",
       "      <td>-0.076089</td>\n",
       "      <td>-0.061724</td>\n",
       "      <td>0.009549</td>\n",
       "      <td>0.039809</td>\n",
       "      <td>0.057906</td>\n",
       "      <td>0.041327</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>-0.020231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>-0.039698</td>\n",
       "      <td>0.063765</td>\n",
       "      <td>0.118363</td>\n",
       "      <td>0.140928</td>\n",
       "      <td>0.152761</td>\n",
       "      <td>0.125845</td>\n",
       "      <td>0.114529</td>\n",
       "      <td>0.113929</td>\n",
       "      <td>0.107155</td>\n",
       "      <td>0.098008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0.153398</td>\n",
       "      <td>0.110778</td>\n",
       "      <td>0.080120</td>\n",
       "      <td>0.065841</td>\n",
       "      <td>0.043615</td>\n",
       "      <td>0.033935</td>\n",
       "      <td>0.012979</td>\n",
       "      <td>-0.002245</td>\n",
       "      <td>-0.008278</td>\n",
       "      <td>-0.021117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             dr1       dr2       dr3       dr4       dr5       dr6       dr7  \\\n",
       "0      -0.209889 -0.187730 -0.169542 -0.155964 -0.100744 -0.049741 -0.011099   \n",
       "1       0.364046  0.430008  0.453121  0.450021  0.374578  0.309706  0.240559   \n",
       "2       0.311775  0.254511  0.227109  0.215286  0.148460  0.112097  0.090454   \n",
       "3       0.033877  0.051836  0.065151  0.073930  0.100935  0.100271  0.094132   \n",
       "4      -0.355428 -0.330448 -0.306125 -0.291701 -0.253399 -0.215256 -0.163749   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "999995  0.022223  0.034349  0.046298  0.047812  0.027945  0.018082  0.012005   \n",
       "999996 -0.178963 -0.188312 -0.189045 -0.187326 -0.182576 -0.170714 -0.155041   \n",
       "999997 -0.164632 -0.113120 -0.076089 -0.061724  0.009549  0.039809  0.057906   \n",
       "999998 -0.039698  0.063765  0.118363  0.140928  0.152761  0.125845  0.114529   \n",
       "999999  0.153398  0.110778  0.080120  0.065841  0.043615  0.033935  0.012979   \n",
       "\n",
       "             dr8       dr9      dr10  labels  \n",
       "0      -0.010984 -0.002834  0.024089       0  \n",
       "1       0.190503  0.174401  0.176335       1  \n",
       "2       0.058546  0.035873  0.043613       1  \n",
       "3       0.080007  0.059981  0.032160       0  \n",
       "4      -0.124680 -0.080408 -0.051999       0  \n",
       "...          ...       ...       ...     ...  \n",
       "999995  0.015623  0.028762  0.036779       0  \n",
       "999996 -0.143078 -0.136640 -0.120222       0  \n",
       "999997  0.041327  0.010610 -0.020231       0  \n",
       "999998  0.113929  0.107155  0.098008       0  \n",
       "999999 -0.002245 -0.008278 -0.021117       0  \n",
       "\n",
       "[1000000 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([dr1, dr2, dr3, dr4, dr5, dr6, dr7, dr8, dr9, dr10, lbl], axis=1, ignore_index=False, sort=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we select a dataframe consisting of evenly separated labels\n",
    "\n",
    "(I'm not sure if selecting all particles will impact in a different result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sorting out the labels consisting in label '0' and label '1'\n",
    "## Then we sample them in order to not selecting them in a specific range or shape\n",
    "\n",
    "df_0 = df.sort_values('labels').head(710036).sample(289000)\n",
    "df_1 = df.sort_values('labels').tail(289964).sample(289000) \n",
    "df_1.labels.sum()\n",
    "df_r = pd.concat([df_0, df_1])\n",
    "\n",
    "\n",
    "randomize = np.random.permutation(len(df_r.values))\n",
    "data = df_r.values[randomize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a size for our traning dataset \n",
    "\n",
    "I think that for 500k + particles we can divide into train, test and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a size for your train set \n",
    "split = 0.8\n",
    "ntrain = int(split * len(data))\n",
    "indx = [ntrain]\n",
    "train_set, test_set = np.split(data, indx)\n",
    "\n",
    "split = 0.5\n",
    "ntrain = int(split * len(test_set))\n",
    "indx = [ntrain]\n",
    "validation_set, test_test = np.split(test_set, indx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select data, X for attributes, y for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set[:, :-1]\n",
    "y_train = train_set[:, -1]\n",
    "\n",
    "X_val = validation_set[:, :-1]\n",
    "y_val = validation_set[:, -1]\n",
    "\n",
    "X_test = test_set[:, :-1]\n",
    "y_test = test_set[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((462400, 10), (57800, 10), (115600, 10), (462400,), (57800,), (115600,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train), np.shape(X_val), np.shape(X_test), np.shape(y_train), np.shape(y_val), np.shape(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57800, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val = y_val.reshape(-1,1)\n",
    "np.shape(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462400, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.reshape(-1,1)\n",
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching hyperparameters with genetic algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [7:01:01<00:00, 2142.89s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best 5 solutions:\n",
      "-----------------\n",
      "\n",
      "   deep  num_units  batch_size      loss     score        time\n",
      "0     4        100         512  0.148364  0.148364  298.439124\n",
      "1     4        100         512  0.148368  0.148368  301.917318\n",
      "2     4        100         512  0.148381  0.148381  301.315263\n",
      "3     4        100         512  0.148392  0.148392  303.483416\n",
      "4     4        200         512  0.148405  0.148405  501.007462\n",
      "[[1, 0, 0, 0]]\n",
      "Total elapsed time: 457.0988372564316 minutes\n"
     ]
    }
   ],
   "source": [
    "population_size = 10  # max of individuals per generation\n",
    "max_generations = 10   # number of generations\n",
    "gene_length = 4        # lenght of the gene, depends on how many hiperparameters are tested\n",
    "k = 1                  # num. of finalist individuals\n",
    "\n",
    "t = time.time()\n",
    "datos = []T\n",
    "\n",
    "# Define the hyperparameters for the search\n",
    "hyperparams = {'deep': [3, 4], 'num_units': [100, 200], 'batch_size': [512, 1024]}\n",
    "\n",
    "# generate a Nnogada instance\n",
    "net_fit = Nnogada(hyp_to_find=hyperparams, X_train=X_train, Y_train=y_train, X_val=X_val, Y_val=y_val, regression=True)\n",
    "# Set the possible values of hyperparameters and not use the default values from hyperparameters.py\n",
    "net_fit.set_hyperparameters()\n",
    "\n",
    "# best solution\n",
    "best_population = net_fit.ga_with_elitism(population_size, max_generations, gene_length, k)\n",
    "print(best_population)\n",
    "print(\"Total elapsed time:\", (time.time()-t)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deep</th>\n",
       "      <th>num_units</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>loss</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>512</td>\n",
       "      <td>0.148364</td>\n",
       "      <td>0.148364</td>\n",
       "      <td>298.439124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>512</td>\n",
       "      <td>0.148368</td>\n",
       "      <td>0.148368</td>\n",
       "      <td>301.917318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>512</td>\n",
       "      <td>0.148381</td>\n",
       "      <td>0.148381</td>\n",
       "      <td>301.315263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>512</td>\n",
       "      <td>0.148392</td>\n",
       "      <td>0.148392</td>\n",
       "      <td>303.483416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>512</td>\n",
       "      <td>0.148405</td>\n",
       "      <td>0.148405</td>\n",
       "      <td>501.007462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.148944</td>\n",
       "      <td>0.148944</td>\n",
       "      <td>158.335883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.149008</td>\n",
       "      <td>0.149008</td>\n",
       "      <td>205.829587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>512</td>\n",
       "      <td>0.149088</td>\n",
       "      <td>0.149088</td>\n",
       "      <td>306.203994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>512</td>\n",
       "      <td>0.149139</td>\n",
       "      <td>0.149139</td>\n",
       "      <td>500.385237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.149195</td>\n",
       "      <td>0.149195</td>\n",
       "      <td>315.790815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    deep  num_units  batch_size      loss     score        time\n",
       "0      4        100         512  0.148364  0.148364  298.439124\n",
       "1      4        100         512  0.148368  0.148368  301.917318\n",
       "2      4        100         512  0.148381  0.148381  301.315263\n",
       "3      4        100         512  0.148392  0.148392  303.483416\n",
       "4      4        200         512  0.148405  0.148405  501.007462\n",
       "..   ...        ...         ...       ...       ...         ...\n",
       "70     3        100        1024  0.148944  0.148944  158.335883\n",
       "71     3        100        1024  0.149008  0.149008  205.829587\n",
       "72     4        100         512  0.149088  0.149088  306.203994\n",
       "73     4        200         512  0.149139  0.149139  500.385237\n",
       "74     3        200        1024  0.149195  0.149195  315.790815\n",
       "\n",
       "[75 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_fit.history.sort_values(by='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the Confusion matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### THIS CELL IS FOR CALCULATE THE CONFUSION MATRIX ####\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_462 (Dense)           (None, 100)               1100      \n",
      "                                                                 \n",
      " dense_463 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_464 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_465 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_466 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,501\n",
      "Trainable params: 31,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#para scikit-learn: (samples,features)\n",
    "#test_input_T = test_input.T\n",
    "#X_train, X_test, y_train, y_test = train_test_split(test_input_T,test_labels,test_size=0.25,random_state=None)\n",
    "\n",
    "#ANN\n",
    "test1_model = models.Sequential()\n",
    "test1_model.add(layers.Dense(100,activation='tanh',input_shape=(10,)))\n",
    "test1_model.add(layers.Dense(100,activation='tanh'))\n",
    "test1_model.add(layers.Dense(100,activation='tanh'))\n",
    "test1_model.add(layers.Dense(100,activation='tanh'))\n",
    "#test1_model.add(layers.Dense(10,activation='relu'))\n",
    "test1_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "test1_model.compile(optimizer=optimizers.Adam(lr=0.001),#RMSprop(lr=0.001),\n",
    "                    loss=losses.mean_squared_error,\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "test1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1551 - accuracy: 0.7759 - val_loss: 0.1505 - val_accuracy: 0.7822\n",
      "Epoch 2/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1511 - accuracy: 0.7814 - val_loss: 0.1495 - val_accuracy: 0.7834\n",
      "Epoch 3/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1510 - accuracy: 0.7816 - val_loss: 0.1499 - val_accuracy: 0.7835\n",
      "Epoch 4/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1509 - accuracy: 0.7814 - val_loss: 0.1495 - val_accuracy: 0.7832\n",
      "Epoch 5/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1507 - accuracy: 0.7818 - val_loss: 0.1495 - val_accuracy: 0.7839\n",
      "Epoch 6/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1508 - accuracy: 0.7820 - val_loss: 0.1497 - val_accuracy: 0.7817\n",
      "Epoch 7/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1506 - accuracy: 0.7820 - val_loss: 0.1493 - val_accuracy: 0.7836\n",
      "Epoch 8/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1506 - accuracy: 0.7820 - val_loss: 0.1495 - val_accuracy: 0.7833\n",
      "Epoch 9/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1505 - accuracy: 0.7818 - val_loss: 0.1503 - val_accuracy: 0.7836\n",
      "Epoch 10/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1505 - accuracy: 0.7820 - val_loss: 0.1492 - val_accuracy: 0.7845\n",
      "Epoch 11/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1504 - accuracy: 0.7821 - val_loss: 0.1493 - val_accuracy: 0.7834\n",
      "Epoch 12/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1503 - accuracy: 0.7822 - val_loss: 0.1492 - val_accuracy: 0.7835\n",
      "Epoch 13/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1503 - accuracy: 0.7822 - val_loss: 0.1494 - val_accuracy: 0.7831\n",
      "Epoch 14/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1502 - accuracy: 0.7824 - val_loss: 0.1492 - val_accuracy: 0.7835\n",
      "Epoch 15/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1502 - accuracy: 0.7824 - val_loss: 0.1492 - val_accuracy: 0.7840\n",
      "Epoch 16/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1501 - accuracy: 0.7826 - val_loss: 0.1489 - val_accuracy: 0.7846\n",
      "Epoch 17/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1500 - accuracy: 0.7827 - val_loss: 0.1491 - val_accuracy: 0.7837\n",
      "Epoch 18/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1500 - accuracy: 0.7827 - val_loss: 0.1490 - val_accuracy: 0.7843\n",
      "Epoch 19/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1499 - accuracy: 0.7827 - val_loss: 0.1488 - val_accuracy: 0.7846\n",
      "Epoch 20/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1499 - accuracy: 0.7827 - val_loss: 0.1491 - val_accuracy: 0.7844\n",
      "Epoch 21/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1499 - accuracy: 0.7829 - val_loss: 0.1488 - val_accuracy: 0.7849\n",
      "Epoch 22/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1498 - accuracy: 0.7831 - val_loss: 0.1496 - val_accuracy: 0.7835\n",
      "Epoch 23/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1498 - accuracy: 0.7829 - val_loss: 0.1490 - val_accuracy: 0.7835\n",
      "Epoch 24/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1497 - accuracy: 0.7830 - val_loss: 0.1483 - val_accuracy: 0.7848\n",
      "Epoch 25/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1496 - accuracy: 0.7833 - val_loss: 0.1485 - val_accuracy: 0.7851\n",
      "Epoch 26/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1496 - accuracy: 0.7832 - val_loss: 0.1484 - val_accuracy: 0.7847\n",
      "Epoch 27/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1496 - accuracy: 0.7832 - val_loss: 0.1485 - val_accuracy: 0.7849\n",
      "Epoch 28/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1495 - accuracy: 0.7831 - val_loss: 0.1487 - val_accuracy: 0.7843\n",
      "Epoch 29/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1495 - accuracy: 0.7834 - val_loss: 0.1487 - val_accuracy: 0.7837\n",
      "Epoch 30/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1494 - accuracy: 0.7835 - val_loss: 0.1484 - val_accuracy: 0.7842\n",
      "Epoch 31/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1494 - accuracy: 0.7835 - val_loss: 0.1484 - val_accuracy: 0.7846\n",
      "Epoch 32/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1493 - accuracy: 0.7835 - val_loss: 0.1483 - val_accuracy: 0.7845\n",
      "Epoch 33/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1493 - accuracy: 0.7834 - val_loss: 0.1485 - val_accuracy: 0.7848\n",
      "Epoch 34/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1493 - accuracy: 0.7838 - val_loss: 0.1481 - val_accuracy: 0.7854\n",
      "Epoch 35/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1492 - accuracy: 0.7841 - val_loss: 0.1483 - val_accuracy: 0.7841\n",
      "Epoch 36/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1491 - accuracy: 0.7841 - val_loss: 0.1483 - val_accuracy: 0.7860\n",
      "Epoch 37/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1491 - accuracy: 0.7840 - val_loss: 0.1485 - val_accuracy: 0.7848\n",
      "Epoch 38/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1490 - accuracy: 0.7840 - val_loss: 0.1482 - val_accuracy: 0.7849\n",
      "Epoch 39/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1490 - accuracy: 0.7842 - val_loss: 0.1481 - val_accuracy: 0.7854\n",
      "Epoch 40/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1489 - accuracy: 0.7842 - val_loss: 0.1481 - val_accuracy: 0.7843\n",
      "Epoch 41/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1489 - accuracy: 0.7841 - val_loss: 0.1481 - val_accuracy: 0.7865\n",
      "Epoch 42/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1488 - accuracy: 0.7844 - val_loss: 0.1483 - val_accuracy: 0.7848\n",
      "Epoch 43/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1488 - accuracy: 0.7848 - val_loss: 0.1484 - val_accuracy: 0.7849\n",
      "Epoch 44/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1487 - accuracy: 0.7849 - val_loss: 0.1478 - val_accuracy: 0.7861\n",
      "Epoch 45/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1487 - accuracy: 0.7847 - val_loss: 0.1480 - val_accuracy: 0.7854\n",
      "Epoch 46/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1486 - accuracy: 0.7848 - val_loss: 0.1482 - val_accuracy: 0.7855\n",
      "Epoch 47/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1485 - accuracy: 0.7851 - val_loss: 0.1479 - val_accuracy: 0.7862\n",
      "Epoch 48/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1485 - accuracy: 0.7848 - val_loss: 0.1479 - val_accuracy: 0.7870\n",
      "Epoch 49/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1484 - accuracy: 0.7850 - val_loss: 0.1479 - val_accuracy: 0.7852\n",
      "Epoch 50/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1483 - accuracy: 0.7854 - val_loss: 0.1479 - val_accuracy: 0.7853\n",
      "Epoch 51/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1482 - accuracy: 0.7857 - val_loss: 0.1482 - val_accuracy: 0.7853\n",
      "Epoch 52/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1482 - accuracy: 0.7856 - val_loss: 0.1477 - val_accuracy: 0.7860\n",
      "Epoch 53/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1481 - accuracy: 0.7857 - val_loss: 0.1478 - val_accuracy: 0.7860\n",
      "Epoch 54/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1481 - accuracy: 0.7860 - val_loss: 0.1479 - val_accuracy: 0.7862\n",
      "Epoch 55/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1480 - accuracy: 0.7860 - val_loss: 0.1476 - val_accuracy: 0.7871\n",
      "Epoch 56/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1479 - accuracy: 0.7862 - val_loss: 0.1480 - val_accuracy: 0.7859\n",
      "Epoch 57/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1478 - accuracy: 0.7863 - val_loss: 0.1477 - val_accuracy: 0.7860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1478 - accuracy: 0.7864 - val_loss: 0.1476 - val_accuracy: 0.7875\n",
      "Epoch 59/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1476 - accuracy: 0.7868 - val_loss: 0.1478 - val_accuracy: 0.7855\n",
      "Epoch 60/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1476 - accuracy: 0.7869 - val_loss: 0.1478 - val_accuracy: 0.7862\n",
      "Epoch 61/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1475 - accuracy: 0.7870 - val_loss: 0.1476 - val_accuracy: 0.7855\n",
      "Epoch 62/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1474 - accuracy: 0.7873 - val_loss: 0.1474 - val_accuracy: 0.7864\n",
      "Epoch 63/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1473 - accuracy: 0.7873 - val_loss: 0.1481 - val_accuracy: 0.7855\n",
      "Epoch 64/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1472 - accuracy: 0.7873 - val_loss: 0.1474 - val_accuracy: 0.7862\n",
      "Epoch 65/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1471 - accuracy: 0.7873 - val_loss: 0.1478 - val_accuracy: 0.7861\n",
      "Epoch 66/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1471 - accuracy: 0.7876 - val_loss: 0.1479 - val_accuracy: 0.7862\n",
      "Epoch 67/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1470 - accuracy: 0.7881 - val_loss: 0.1476 - val_accuracy: 0.7865\n",
      "Epoch 68/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1468 - accuracy: 0.7883 - val_loss: 0.1473 - val_accuracy: 0.7877\n",
      "Epoch 69/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1468 - accuracy: 0.7884 - val_loss: 0.1472 - val_accuracy: 0.7869\n",
      "Epoch 70/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1467 - accuracy: 0.7883 - val_loss: 0.1473 - val_accuracy: 0.7873\n",
      "Epoch 71/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1466 - accuracy: 0.7887 - val_loss: 0.1471 - val_accuracy: 0.7870\n",
      "Epoch 72/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1465 - accuracy: 0.7888 - val_loss: 0.1473 - val_accuracy: 0.7869\n",
      "Epoch 73/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1464 - accuracy: 0.7890 - val_loss: 0.1476 - val_accuracy: 0.7863\n",
      "Epoch 74/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1464 - accuracy: 0.7891 - val_loss: 0.1471 - val_accuracy: 0.7883\n",
      "Epoch 75/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1462 - accuracy: 0.7896 - val_loss: 0.1470 - val_accuracy: 0.7875\n",
      "Epoch 76/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1461 - accuracy: 0.7894 - val_loss: 0.1471 - val_accuracy: 0.7888\n",
      "Epoch 77/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1460 - accuracy: 0.7898 - val_loss: 0.1475 - val_accuracy: 0.7869\n",
      "Epoch 78/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1460 - accuracy: 0.7899 - val_loss: 0.1470 - val_accuracy: 0.7876\n",
      "Epoch 79/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1458 - accuracy: 0.7903 - val_loss: 0.1469 - val_accuracy: 0.7890\n",
      "Epoch 80/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1457 - accuracy: 0.7903 - val_loss: 0.1474 - val_accuracy: 0.7865\n",
      "Epoch 81/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1456 - accuracy: 0.7909 - val_loss: 0.1476 - val_accuracy: 0.7866\n",
      "Epoch 82/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1455 - accuracy: 0.7907 - val_loss: 0.1466 - val_accuracy: 0.7890\n",
      "Epoch 83/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1454 - accuracy: 0.7912 - val_loss: 0.1469 - val_accuracy: 0.7890\n",
      "Epoch 84/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1453 - accuracy: 0.7912 - val_loss: 0.1469 - val_accuracy: 0.7884\n",
      "Epoch 85/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1452 - accuracy: 0.7914 - val_loss: 0.1470 - val_accuracy: 0.7876\n",
      "Epoch 86/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1451 - accuracy: 0.7915 - val_loss: 0.1467 - val_accuracy: 0.7877\n",
      "Epoch 87/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1449 - accuracy: 0.7917 - val_loss: 0.1468 - val_accuracy: 0.7881\n",
      "Epoch 88/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1449 - accuracy: 0.7922 - val_loss: 0.1468 - val_accuracy: 0.7884\n",
      "Epoch 89/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1447 - accuracy: 0.7922 - val_loss: 0.1466 - val_accuracy: 0.7886\n",
      "Epoch 90/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1446 - accuracy: 0.7927 - val_loss: 0.1465 - val_accuracy: 0.7894\n",
      "Epoch 91/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1445 - accuracy: 0.7929 - val_loss: 0.1469 - val_accuracy: 0.7894\n",
      "Epoch 92/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1444 - accuracy: 0.7929 - val_loss: 0.1464 - val_accuracy: 0.7893\n",
      "Epoch 93/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1442 - accuracy: 0.7931 - val_loss: 0.1467 - val_accuracy: 0.7889\n",
      "Epoch 94/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1441 - accuracy: 0.7933 - val_loss: 0.1466 - val_accuracy: 0.7891\n",
      "Epoch 95/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1440 - accuracy: 0.7937 - val_loss: 0.1464 - val_accuracy: 0.7897\n",
      "Epoch 96/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1439 - accuracy: 0.7939 - val_loss: 0.1465 - val_accuracy: 0.7890\n",
      "Epoch 97/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1437 - accuracy: 0.7944 - val_loss: 0.1465 - val_accuracy: 0.7893\n",
      "Epoch 98/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1437 - accuracy: 0.7941 - val_loss: 0.1464 - val_accuracy: 0.7895\n",
      "Epoch 99/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1436 - accuracy: 0.7943 - val_loss: 0.1462 - val_accuracy: 0.7898\n",
      "Epoch 100/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1434 - accuracy: 0.7950 - val_loss: 0.1463 - val_accuracy: 0.7896\n",
      "Epoch 101/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1433 - accuracy: 0.7949 - val_loss: 0.1466 - val_accuracy: 0.7890\n",
      "Epoch 102/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1432 - accuracy: 0.7946 - val_loss: 0.1462 - val_accuracy: 0.7896\n",
      "Epoch 103/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1430 - accuracy: 0.7957 - val_loss: 0.1463 - val_accuracy: 0.7896\n",
      "Epoch 104/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1428 - accuracy: 0.7958 - val_loss: 0.1465 - val_accuracy: 0.7897\n",
      "Epoch 105/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1427 - accuracy: 0.7963 - val_loss: 0.1461 - val_accuracy: 0.7901\n",
      "Epoch 106/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1426 - accuracy: 0.7962 - val_loss: 0.1461 - val_accuracy: 0.7904\n",
      "Epoch 107/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1425 - accuracy: 0.7963 - val_loss: 0.1458 - val_accuracy: 0.7913\n",
      "Epoch 108/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1422 - accuracy: 0.7969 - val_loss: 0.1459 - val_accuracy: 0.7905\n",
      "Epoch 109/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1421 - accuracy: 0.7972 - val_loss: 0.1458 - val_accuracy: 0.7909\n",
      "Epoch 110/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1420 - accuracy: 0.7973 - val_loss: 0.1464 - val_accuracy: 0.7892\n",
      "Epoch 111/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1418 - accuracy: 0.7980 - val_loss: 0.1455 - val_accuracy: 0.7911\n",
      "Epoch 112/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1417 - accuracy: 0.7978 - val_loss: 0.1458 - val_accuracy: 0.7907\n",
      "Epoch 113/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1415 - accuracy: 0.7987 - val_loss: 0.1459 - val_accuracy: 0.7911\n",
      "Epoch 114/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1413 - accuracy: 0.7986 - val_loss: 0.1459 - val_accuracy: 0.7921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1412 - accuracy: 0.7992 - val_loss: 0.1457 - val_accuracy: 0.7916\n",
      "Epoch 116/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1411 - accuracy: 0.7989 - val_loss: 0.1455 - val_accuracy: 0.7903\n",
      "Epoch 117/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1408 - accuracy: 0.7997 - val_loss: 0.1457 - val_accuracy: 0.7919\n",
      "Epoch 118/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1407 - accuracy: 0.8000 - val_loss: 0.1452 - val_accuracy: 0.7914\n",
      "Epoch 119/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1405 - accuracy: 0.8001 - val_loss: 0.1453 - val_accuracy: 0.7925\n",
      "Epoch 120/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1403 - accuracy: 0.8006 - val_loss: 0.1455 - val_accuracy: 0.7923\n",
      "Epoch 121/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1402 - accuracy: 0.8006 - val_loss: 0.1454 - val_accuracy: 0.7924\n",
      "Epoch 122/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1400 - accuracy: 0.8011 - val_loss: 0.1451 - val_accuracy: 0.7928\n",
      "Epoch 123/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1398 - accuracy: 0.8016 - val_loss: 0.1459 - val_accuracy: 0.7904\n",
      "Epoch 124/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1397 - accuracy: 0.8019 - val_loss: 0.1452 - val_accuracy: 0.7929\n",
      "Epoch 125/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1395 - accuracy: 0.8025 - val_loss: 0.1453 - val_accuracy: 0.7930\n",
      "Epoch 126/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1392 - accuracy: 0.8028 - val_loss: 0.1449 - val_accuracy: 0.7933\n",
      "Epoch 127/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1392 - accuracy: 0.8030 - val_loss: 0.1449 - val_accuracy: 0.7930\n",
      "Epoch 128/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1389 - accuracy: 0.8034 - val_loss: 0.1448 - val_accuracy: 0.7941\n",
      "Epoch 129/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1388 - accuracy: 0.8039 - val_loss: 0.1446 - val_accuracy: 0.7942\n",
      "Epoch 130/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1386 - accuracy: 0.8041 - val_loss: 0.1450 - val_accuracy: 0.7930\n",
      "Epoch 131/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1384 - accuracy: 0.8044 - val_loss: 0.1447 - val_accuracy: 0.7936\n",
      "Epoch 132/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1383 - accuracy: 0.8041 - val_loss: 0.1452 - val_accuracy: 0.7931\n",
      "Epoch 133/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1379 - accuracy: 0.8050 - val_loss: 0.1447 - val_accuracy: 0.7940\n",
      "Epoch 134/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1377 - accuracy: 0.8055 - val_loss: 0.1447 - val_accuracy: 0.7947\n",
      "Epoch 135/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1376 - accuracy: 0.8060 - val_loss: 0.1445 - val_accuracy: 0.7949\n",
      "Epoch 136/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1375 - accuracy: 0.8062 - val_loss: 0.1449 - val_accuracy: 0.7941\n",
      "Epoch 137/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1373 - accuracy: 0.8062 - val_loss: 0.1450 - val_accuracy: 0.7931\n",
      "Epoch 138/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1371 - accuracy: 0.8068 - val_loss: 0.1451 - val_accuracy: 0.7949\n",
      "Epoch 139/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1369 - accuracy: 0.8072 - val_loss: 0.1451 - val_accuracy: 0.7934\n",
      "Epoch 140/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1367 - accuracy: 0.8074 - val_loss: 0.1443 - val_accuracy: 0.7958\n",
      "Epoch 141/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1365 - accuracy: 0.8079 - val_loss: 0.1451 - val_accuracy: 0.7930\n",
      "Epoch 142/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1364 - accuracy: 0.8084 - val_loss: 0.1445 - val_accuracy: 0.7941\n",
      "Epoch 143/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1362 - accuracy: 0.8083 - val_loss: 0.1445 - val_accuracy: 0.7951\n",
      "Epoch 144/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1360 - accuracy: 0.8085 - val_loss: 0.1443 - val_accuracy: 0.7962\n",
      "Epoch 145/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1359 - accuracy: 0.8088 - val_loss: 0.1440 - val_accuracy: 0.7969\n",
      "Epoch 146/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1357 - accuracy: 0.8093 - val_loss: 0.1444 - val_accuracy: 0.7965\n",
      "Epoch 147/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1356 - accuracy: 0.8097 - val_loss: 0.1440 - val_accuracy: 0.7959\n",
      "Epoch 148/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1353 - accuracy: 0.8104 - val_loss: 0.1441 - val_accuracy: 0.7962\n",
      "Epoch 149/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1352 - accuracy: 0.8105 - val_loss: 0.1454 - val_accuracy: 0.7944\n",
      "Epoch 150/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1351 - accuracy: 0.8100 - val_loss: 0.1444 - val_accuracy: 0.7957\n",
      "Epoch 151/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1349 - accuracy: 0.8108 - val_loss: 0.1443 - val_accuracy: 0.7960\n",
      "Epoch 152/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1347 - accuracy: 0.8115 - val_loss: 0.1438 - val_accuracy: 0.7962\n",
      "Epoch 153/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1345 - accuracy: 0.8122 - val_loss: 0.1441 - val_accuracy: 0.7967\n",
      "Epoch 154/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1344 - accuracy: 0.8121 - val_loss: 0.1440 - val_accuracy: 0.7972\n",
      "Epoch 155/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1342 - accuracy: 0.8124 - val_loss: 0.1445 - val_accuracy: 0.7943\n",
      "Epoch 156/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1340 - accuracy: 0.8130 - val_loss: 0.1440 - val_accuracy: 0.7962\n",
      "Epoch 157/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1338 - accuracy: 0.8131 - val_loss: 0.1432 - val_accuracy: 0.7984\n",
      "Epoch 158/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1337 - accuracy: 0.8137 - val_loss: 0.1443 - val_accuracy: 0.7963\n",
      "Epoch 159/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1334 - accuracy: 0.8138 - val_loss: 0.1440 - val_accuracy: 0.7978\n",
      "Epoch 160/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1333 - accuracy: 0.8140 - val_loss: 0.1433 - val_accuracy: 0.7987\n",
      "Epoch 161/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1332 - accuracy: 0.8144 - val_loss: 0.1436 - val_accuracy: 0.7967\n",
      "Epoch 162/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1330 - accuracy: 0.8149 - val_loss: 0.1434 - val_accuracy: 0.7980\n",
      "Epoch 163/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1328 - accuracy: 0.8149 - val_loss: 0.1432 - val_accuracy: 0.7984\n",
      "Epoch 164/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1328 - accuracy: 0.8150 - val_loss: 0.1436 - val_accuracy: 0.7978\n",
      "Epoch 165/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1325 - accuracy: 0.8160 - val_loss: 0.1438 - val_accuracy: 0.7969\n",
      "Epoch 166/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1324 - accuracy: 0.8157 - val_loss: 0.1429 - val_accuracy: 0.7994\n",
      "Epoch 167/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1323 - accuracy: 0.8157 - val_loss: 0.1437 - val_accuracy: 0.7981\n",
      "Epoch 168/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1321 - accuracy: 0.8166 - val_loss: 0.1431 - val_accuracy: 0.7984\n",
      "Epoch 169/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1319 - accuracy: 0.8170 - val_loss: 0.1436 - val_accuracy: 0.7972\n",
      "Epoch 170/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1319 - accuracy: 0.8168 - val_loss: 0.1435 - val_accuracy: 0.7981\n",
      "Epoch 171/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1317 - accuracy: 0.8173 - val_loss: 0.1437 - val_accuracy: 0.7982\n",
      "Epoch 172/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1315 - accuracy: 0.8177 - val_loss: 0.1434 - val_accuracy: 0.7986\n",
      "Epoch 173/500\n",
      "904/904 [==============================] - 4s 5ms/step - loss: 0.1313 - accuracy: 0.8183 - val_loss: 0.1428 - val_accuracy: 0.7999\n",
      "Epoch 174/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1311 - accuracy: 0.8186 - val_loss: 0.1435 - val_accuracy: 0.7993\n",
      "Epoch 175/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1312 - accuracy: 0.8185 - val_loss: 0.1435 - val_accuracy: 0.7994\n",
      "Epoch 176/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1309 - accuracy: 0.8187 - val_loss: 0.1430 - val_accuracy: 0.7998\n",
      "Epoch 177/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1308 - accuracy: 0.8187 - val_loss: 0.1436 - val_accuracy: 0.7989\n",
      "Epoch 178/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1306 - accuracy: 0.8190 - val_loss: 0.1437 - val_accuracy: 0.7979\n",
      "Epoch 179/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1306 - accuracy: 0.8196 - val_loss: 0.1427 - val_accuracy: 0.7992\n",
      "Epoch 180/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1303 - accuracy: 0.8198 - val_loss: 0.1440 - val_accuracy: 0.7978\n",
      "Epoch 181/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1302 - accuracy: 0.8202 - val_loss: 0.1429 - val_accuracy: 0.7993\n",
      "Epoch 182/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1300 - accuracy: 0.8205 - val_loss: 0.1431 - val_accuracy: 0.7985\n",
      "Epoch 183/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1300 - accuracy: 0.8207 - val_loss: 0.1442 - val_accuracy: 0.7974\n",
      "Epoch 184/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1299 - accuracy: 0.8207 - val_loss: 0.1430 - val_accuracy: 0.7993\n",
      "Epoch 185/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1295 - accuracy: 0.8212 - val_loss: 0.1429 - val_accuracy: 0.7997\n",
      "Epoch 186/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1294 - accuracy: 0.8218 - val_loss: 0.1423 - val_accuracy: 0.8003\n",
      "Epoch 187/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1293 - accuracy: 0.8216 - val_loss: 0.1431 - val_accuracy: 0.8002\n",
      "Epoch 188/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1292 - accuracy: 0.8220 - val_loss: 0.1426 - val_accuracy: 0.8004\n",
      "Epoch 189/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1290 - accuracy: 0.8221 - val_loss: 0.1427 - val_accuracy: 0.8005\n",
      "Epoch 190/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1290 - accuracy: 0.8226 - val_loss: 0.1429 - val_accuracy: 0.7992\n",
      "Epoch 191/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1288 - accuracy: 0.8224 - val_loss: 0.1424 - val_accuracy: 0.8025\n",
      "Epoch 192/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1285 - accuracy: 0.8238 - val_loss: 0.1430 - val_accuracy: 0.8005\n",
      "Epoch 193/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1284 - accuracy: 0.8236 - val_loss: 0.1427 - val_accuracy: 0.8003\n",
      "Epoch 194/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1283 - accuracy: 0.8234 - val_loss: 0.1437 - val_accuracy: 0.7974\n",
      "Epoch 195/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1281 - accuracy: 0.8244 - val_loss: 0.1435 - val_accuracy: 0.7975\n",
      "Epoch 196/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1281 - accuracy: 0.8240 - val_loss: 0.1429 - val_accuracy: 0.7996\n",
      "Epoch 197/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1279 - accuracy: 0.8247 - val_loss: 0.1427 - val_accuracy: 0.7991\n",
      "Epoch 198/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1278 - accuracy: 0.8250 - val_loss: 0.1425 - val_accuracy: 0.8000\n",
      "Epoch 199/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1277 - accuracy: 0.8251 - val_loss: 0.1419 - val_accuracy: 0.8031\n",
      "Epoch 200/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1275 - accuracy: 0.8248 - val_loss: 0.1430 - val_accuracy: 0.8006\n",
      "Epoch 201/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1273 - accuracy: 0.8255 - val_loss: 0.1420 - val_accuracy: 0.8014\n",
      "Epoch 202/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1271 - accuracy: 0.8260 - val_loss: 0.1425 - val_accuracy: 0.8013\n",
      "Epoch 203/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1271 - accuracy: 0.8263 - val_loss: 0.1419 - val_accuracy: 0.8024\n",
      "Epoch 204/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1268 - accuracy: 0.8264 - val_loss: 0.1428 - val_accuracy: 0.8010\n",
      "Epoch 205/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1268 - accuracy: 0.8262 - val_loss: 0.1420 - val_accuracy: 0.8015\n",
      "Epoch 206/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1267 - accuracy: 0.8268 - val_loss: 0.1420 - val_accuracy: 0.8017\n",
      "Epoch 207/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1264 - accuracy: 0.8273 - val_loss: 0.1421 - val_accuracy: 0.8014\n",
      "Epoch 208/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1265 - accuracy: 0.8273 - val_loss: 0.1433 - val_accuracy: 0.7999\n",
      "Epoch 209/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1264 - accuracy: 0.8276 - val_loss: 0.1434 - val_accuracy: 0.8007\n",
      "Epoch 210/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1260 - accuracy: 0.8283 - val_loss: 0.1426 - val_accuracy: 0.8030\n",
      "Epoch 211/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1261 - accuracy: 0.8279 - val_loss: 0.1434 - val_accuracy: 0.8007\n",
      "Epoch 212/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1258 - accuracy: 0.8286 - val_loss: 0.1434 - val_accuracy: 0.7997\n",
      "Epoch 213/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1256 - accuracy: 0.8288 - val_loss: 0.1423 - val_accuracy: 0.8013\n",
      "Epoch 214/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1255 - accuracy: 0.8287 - val_loss: 0.1453 - val_accuracy: 0.7960\n",
      "Epoch 215/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1254 - accuracy: 0.8291 - val_loss: 0.1423 - val_accuracy: 0.8033\n",
      "Epoch 216/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1252 - accuracy: 0.8296 - val_loss: 0.1428 - val_accuracy: 0.8020\n",
      "Epoch 217/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1252 - accuracy: 0.8295 - val_loss: 0.1429 - val_accuracy: 0.8016\n",
      "Epoch 218/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1250 - accuracy: 0.8298 - val_loss: 0.1435 - val_accuracy: 0.8012\n",
      "Epoch 219/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1250 - accuracy: 0.8301 - val_loss: 0.1425 - val_accuracy: 0.8013\n",
      "Epoch 220/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1248 - accuracy: 0.8305 - val_loss: 0.1421 - val_accuracy: 0.8044\n",
      "Epoch 221/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1247 - accuracy: 0.8304 - val_loss: 0.1417 - val_accuracy: 0.8046\n",
      "Epoch 222/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1246 - accuracy: 0.8305 - val_loss: 0.1418 - val_accuracy: 0.8034\n",
      "Epoch 223/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1243 - accuracy: 0.8311 - val_loss: 0.1419 - val_accuracy: 0.8047\n",
      "Epoch 224/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1242 - accuracy: 0.8319 - val_loss: 0.1412 - val_accuracy: 0.8048\n",
      "Epoch 225/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1242 - accuracy: 0.8313 - val_loss: 0.1423 - val_accuracy: 0.8020\n",
      "Epoch 226/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1240 - accuracy: 0.8317 - val_loss: 0.1423 - val_accuracy: 0.8026\n",
      "Epoch 227/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1239 - accuracy: 0.8321 - val_loss: 0.1421 - val_accuracy: 0.8044\n",
      "Epoch 228/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1237 - accuracy: 0.8322 - val_loss: 0.1422 - val_accuracy: 0.8040\n",
      "Epoch 229/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1238 - accuracy: 0.8324 - val_loss: 0.1422 - val_accuracy: 0.8050\n",
      "Epoch 230/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1236 - accuracy: 0.8328 - val_loss: 0.1418 - val_accuracy: 0.8040\n",
      "Epoch 231/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1235 - accuracy: 0.8328 - val_loss: 0.1431 - val_accuracy: 0.8026\n",
      "Epoch 232/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1234 - accuracy: 0.8329 - val_loss: 0.1425 - val_accuracy: 0.8021\n",
      "Epoch 233/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1233 - accuracy: 0.8329 - val_loss: 0.1414 - val_accuracy: 0.8042\n",
      "Epoch 234/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1231 - accuracy: 0.8339 - val_loss: 0.1425 - val_accuracy: 0.8026\n",
      "Epoch 235/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1230 - accuracy: 0.8336 - val_loss: 0.1418 - val_accuracy: 0.8046\n",
      "Epoch 236/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1230 - accuracy: 0.8339 - val_loss: 0.1420 - val_accuracy: 0.8054\n",
      "Epoch 237/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1227 - accuracy: 0.8345 - val_loss: 0.1415 - val_accuracy: 0.8046\n",
      "Epoch 238/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1227 - accuracy: 0.8339 - val_loss: 0.1416 - val_accuracy: 0.8055\n",
      "Epoch 239/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1225 - accuracy: 0.8346 - val_loss: 0.1416 - val_accuracy: 0.8051\n",
      "Epoch 240/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1225 - accuracy: 0.8345 - val_loss: 0.1426 - val_accuracy: 0.8016\n",
      "Epoch 241/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1222 - accuracy: 0.8352 - val_loss: 0.1415 - val_accuracy: 0.8060\n",
      "Epoch 242/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1224 - accuracy: 0.8351 - val_loss: 0.1427 - val_accuracy: 0.8029\n",
      "Epoch 243/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1222 - accuracy: 0.8355 - val_loss: 0.1425 - val_accuracy: 0.8034\n",
      "Epoch 244/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1220 - accuracy: 0.8358 - val_loss: 0.1413 - val_accuracy: 0.8052\n",
      "Epoch 245/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1219 - accuracy: 0.8356 - val_loss: 0.1417 - val_accuracy: 0.8065\n",
      "Epoch 246/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1218 - accuracy: 0.8360 - val_loss: 0.1420 - val_accuracy: 0.8043\n",
      "Epoch 247/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1217 - accuracy: 0.8362 - val_loss: 0.1426 - val_accuracy: 0.8035\n",
      "Epoch 248/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1214 - accuracy: 0.8371 - val_loss: 0.1427 - val_accuracy: 0.8050\n",
      "Epoch 249/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1214 - accuracy: 0.8371 - val_loss: 0.1421 - val_accuracy: 0.8051\n",
      "Epoch 250/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1214 - accuracy: 0.8368 - val_loss: 0.1412 - val_accuracy: 0.8069\n",
      "Epoch 251/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1211 - accuracy: 0.8373 - val_loss: 0.1417 - val_accuracy: 0.8065\n",
      "Epoch 252/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1211 - accuracy: 0.8374 - val_loss: 0.1422 - val_accuracy: 0.8053\n",
      "Epoch 253/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1209 - accuracy: 0.8376 - val_loss: 0.1410 - val_accuracy: 0.8064\n",
      "Epoch 254/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1212 - accuracy: 0.8371 - val_loss: 0.1412 - val_accuracy: 0.8081\n",
      "Epoch 255/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1208 - accuracy: 0.8378 - val_loss: 0.1416 - val_accuracy: 0.8064\n",
      "Epoch 256/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1206 - accuracy: 0.8380 - val_loss: 0.1415 - val_accuracy: 0.8081\n",
      "Epoch 257/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1206 - accuracy: 0.8385 - val_loss: 0.1413 - val_accuracy: 0.8065\n",
      "Epoch 258/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1205 - accuracy: 0.8383 - val_loss: 0.1430 - val_accuracy: 0.8039\n",
      "Epoch 259/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1203 - accuracy: 0.8388 - val_loss: 0.1413 - val_accuracy: 0.8067\n",
      "Epoch 260/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1201 - accuracy: 0.8391 - val_loss: 0.1415 - val_accuracy: 0.8078\n",
      "Epoch 261/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1201 - accuracy: 0.8392 - val_loss: 0.1409 - val_accuracy: 0.8092\n",
      "Epoch 262/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1199 - accuracy: 0.8394 - val_loss: 0.1421 - val_accuracy: 0.8060\n",
      "Epoch 263/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1200 - accuracy: 0.8391 - val_loss: 0.1414 - val_accuracy: 0.8068\n",
      "Epoch 264/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1198 - accuracy: 0.8398 - val_loss: 0.1418 - val_accuracy: 0.8073\n",
      "Epoch 265/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1197 - accuracy: 0.8399 - val_loss: 0.1416 - val_accuracy: 0.8066\n",
      "Epoch 266/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1196 - accuracy: 0.8399 - val_loss: 0.1419 - val_accuracy: 0.8067\n",
      "Epoch 267/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1194 - accuracy: 0.8404 - val_loss: 0.1420 - val_accuracy: 0.8054\n",
      "Epoch 268/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1194 - accuracy: 0.8404 - val_loss: 0.1416 - val_accuracy: 0.8066\n",
      "Epoch 269/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1192 - accuracy: 0.8409 - val_loss: 0.1417 - val_accuracy: 0.8070\n",
      "Epoch 270/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1191 - accuracy: 0.8410 - val_loss: 0.1410 - val_accuracy: 0.8075\n",
      "Epoch 271/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1190 - accuracy: 0.8411 - val_loss: 0.1409 - val_accuracy: 0.8092\n",
      "Epoch 272/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1189 - accuracy: 0.8410 - val_loss: 0.1422 - val_accuracy: 0.8063\n",
      "Epoch 273/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1186 - accuracy: 0.8419 - val_loss: 0.1433 - val_accuracy: 0.8053\n",
      "Epoch 274/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1188 - accuracy: 0.8418 - val_loss: 0.1417 - val_accuracy: 0.8077\n",
      "Epoch 275/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1186 - accuracy: 0.8423 - val_loss: 0.1407 - val_accuracy: 0.8098\n",
      "Epoch 276/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1185 - accuracy: 0.8417 - val_loss: 0.1410 - val_accuracy: 0.8088\n",
      "Epoch 277/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1184 - accuracy: 0.8421 - val_loss: 0.1412 - val_accuracy: 0.8100\n",
      "Epoch 278/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1182 - accuracy: 0.8426 - val_loss: 0.1411 - val_accuracy: 0.8095\n",
      "Epoch 279/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1181 - accuracy: 0.8424 - val_loss: 0.1413 - val_accuracy: 0.8079\n",
      "Epoch 280/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1180 - accuracy: 0.8429 - val_loss: 0.1409 - val_accuracy: 0.8101\n",
      "Epoch 281/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1179 - accuracy: 0.8430 - val_loss: 0.1418 - val_accuracy: 0.8066\n",
      "Epoch 282/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1180 - accuracy: 0.8430 - val_loss: 0.1412 - val_accuracy: 0.8073\n",
      "Epoch 283/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1179 - accuracy: 0.8432 - val_loss: 0.1418 - val_accuracy: 0.8078\n",
      "Epoch 284/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1178 - accuracy: 0.8433 - val_loss: 0.1416 - val_accuracy: 0.8097\n",
      "Epoch 285/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1176 - accuracy: 0.8440 - val_loss: 0.1409 - val_accuracy: 0.8095\n",
      "Epoch 286/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1175 - accuracy: 0.8441 - val_loss: 0.1420 - val_accuracy: 0.8086\n",
      "Epoch 287/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1175 - accuracy: 0.8439 - val_loss: 0.1415 - val_accuracy: 0.8085\n",
      "Epoch 288/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1174 - accuracy: 0.8438 - val_loss: 0.1425 - val_accuracy: 0.8079\n",
      "Epoch 289/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1173 - accuracy: 0.8444 - val_loss: 0.1417 - val_accuracy: 0.8067\n",
      "Epoch 290/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1173 - accuracy: 0.8444 - val_loss: 0.1403 - val_accuracy: 0.8120\n",
      "Epoch 291/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1171 - accuracy: 0.8450 - val_loss: 0.1420 - val_accuracy: 0.8084\n",
      "Epoch 292/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1169 - accuracy: 0.8447 - val_loss: 0.1413 - val_accuracy: 0.8096\n",
      "Epoch 293/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1167 - accuracy: 0.8451 - val_loss: 0.1413 - val_accuracy: 0.8094\n",
      "Epoch 294/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1167 - accuracy: 0.8454 - val_loss: 0.1421 - val_accuracy: 0.8079\n",
      "Epoch 295/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1167 - accuracy: 0.8456 - val_loss: 0.1417 - val_accuracy: 0.8087\n",
      "Epoch 296/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1165 - accuracy: 0.8459 - val_loss: 0.1413 - val_accuracy: 0.8100\n",
      "Epoch 297/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1165 - accuracy: 0.8460 - val_loss: 0.1419 - val_accuracy: 0.8082\n",
      "Epoch 298/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1164 - accuracy: 0.8458 - val_loss: 0.1428 - val_accuracy: 0.8062\n",
      "Epoch 299/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1162 - accuracy: 0.8463 - val_loss: 0.1417 - val_accuracy: 0.8083\n",
      "Epoch 300/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1161 - accuracy: 0.8466 - val_loss: 0.1416 - val_accuracy: 0.8079\n",
      "Epoch 301/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1161 - accuracy: 0.8462 - val_loss: 0.1425 - val_accuracy: 0.8060\n",
      "Epoch 302/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1160 - accuracy: 0.8468 - val_loss: 0.1409 - val_accuracy: 0.8104\n",
      "Epoch 303/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1161 - accuracy: 0.8469 - val_loss: 0.1411 - val_accuracy: 0.8096\n",
      "Epoch 304/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1158 - accuracy: 0.8468 - val_loss: 0.1416 - val_accuracy: 0.8093\n",
      "Epoch 305/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1158 - accuracy: 0.8467 - val_loss: 0.1425 - val_accuracy: 0.8075\n",
      "Epoch 306/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1158 - accuracy: 0.8469 - val_loss: 0.1408 - val_accuracy: 0.8112\n",
      "Epoch 307/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1158 - accuracy: 0.8470 - val_loss: 0.1431 - val_accuracy: 0.8053\n",
      "Epoch 308/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1156 - accuracy: 0.8472 - val_loss: 0.1409 - val_accuracy: 0.8120\n",
      "Epoch 309/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1154 - accuracy: 0.8475 - val_loss: 0.1411 - val_accuracy: 0.8093\n",
      "Epoch 310/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1154 - accuracy: 0.8477 - val_loss: 0.1430 - val_accuracy: 0.8065\n",
      "Epoch 311/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1154 - accuracy: 0.8478 - val_loss: 0.1400 - val_accuracy: 0.8128\n",
      "Epoch 312/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1152 - accuracy: 0.8477 - val_loss: 0.1409 - val_accuracy: 0.8106\n",
      "Epoch 313/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1153 - accuracy: 0.8478 - val_loss: 0.1413 - val_accuracy: 0.8101\n",
      "Epoch 314/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1151 - accuracy: 0.8484 - val_loss: 0.1427 - val_accuracy: 0.8097\n",
      "Epoch 315/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1149 - accuracy: 0.8484 - val_loss: 0.1406 - val_accuracy: 0.8126\n",
      "Epoch 316/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1150 - accuracy: 0.8486 - val_loss: 0.1405 - val_accuracy: 0.8128\n",
      "Epoch 317/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1150 - accuracy: 0.8487 - val_loss: 0.1438 - val_accuracy: 0.8062\n",
      "Epoch 318/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1150 - accuracy: 0.8480 - val_loss: 0.1415 - val_accuracy: 0.8101\n",
      "Epoch 319/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1145 - accuracy: 0.8496 - val_loss: 0.1412 - val_accuracy: 0.8101\n",
      "Epoch 320/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1146 - accuracy: 0.8489 - val_loss: 0.1417 - val_accuracy: 0.8094\n",
      "Epoch 321/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1145 - accuracy: 0.8493 - val_loss: 0.1421 - val_accuracy: 0.8098\n",
      "Epoch 322/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1147 - accuracy: 0.8489 - val_loss: 0.1401 - val_accuracy: 0.8126\n",
      "Epoch 323/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1143 - accuracy: 0.8498 - val_loss: 0.1405 - val_accuracy: 0.8124\n",
      "Epoch 324/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1144 - accuracy: 0.8497 - val_loss: 0.1415 - val_accuracy: 0.8110\n",
      "Epoch 325/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1142 - accuracy: 0.8495 - val_loss: 0.1403 - val_accuracy: 0.8126\n",
      "Epoch 326/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1143 - accuracy: 0.8497 - val_loss: 0.1418 - val_accuracy: 0.8092\n",
      "Epoch 327/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1141 - accuracy: 0.8498 - val_loss: 0.1402 - val_accuracy: 0.8122\n",
      "Epoch 328/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1143 - accuracy: 0.8495 - val_loss: 0.1414 - val_accuracy: 0.8099\n",
      "Epoch 329/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1140 - accuracy: 0.8505 - val_loss: 0.1402 - val_accuracy: 0.8134\n",
      "Epoch 330/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1140 - accuracy: 0.8498 - val_loss: 0.1405 - val_accuracy: 0.8119\n",
      "Epoch 331/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1138 - accuracy: 0.8505 - val_loss: 0.1417 - val_accuracy: 0.8090\n",
      "Epoch 332/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1137 - accuracy: 0.8507 - val_loss: 0.1422 - val_accuracy: 0.8104\n",
      "Epoch 333/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1138 - accuracy: 0.8502 - val_loss: 0.1405 - val_accuracy: 0.8128\n",
      "Epoch 334/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1136 - accuracy: 0.8505 - val_loss: 0.1420 - val_accuracy: 0.8097\n",
      "Epoch 335/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1137 - accuracy: 0.8507 - val_loss: 0.1408 - val_accuracy: 0.8122\n",
      "Epoch 336/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1135 - accuracy: 0.8507 - val_loss: 0.1409 - val_accuracy: 0.8119\n",
      "Epoch 337/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1135 - accuracy: 0.8510 - val_loss: 0.1412 - val_accuracy: 0.8121\n",
      "Epoch 338/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1134 - accuracy: 0.8508 - val_loss: 0.1404 - val_accuracy: 0.8124\n",
      "Epoch 339/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1133 - accuracy: 0.8508 - val_loss: 0.1409 - val_accuracy: 0.8125\n",
      "Epoch 340/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1134 - accuracy: 0.8510 - val_loss: 0.1425 - val_accuracy: 0.8079\n",
      "Epoch 341/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1132 - accuracy: 0.8513 - val_loss: 0.1411 - val_accuracy: 0.8106\n",
      "Epoch 342/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1131 - accuracy: 0.8513 - val_loss: 0.1424 - val_accuracy: 0.8097\n",
      "Epoch 343/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1131 - accuracy: 0.8516 - val_loss: 0.1408 - val_accuracy: 0.8113\n",
      "Epoch 344/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1127 - accuracy: 0.8525 - val_loss: 0.1429 - val_accuracy: 0.8087\n",
      "Epoch 345/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1129 - accuracy: 0.8519 - val_loss: 0.1406 - val_accuracy: 0.8122\n",
      "Epoch 346/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1128 - accuracy: 0.8522 - val_loss: 0.1411 - val_accuracy: 0.8119\n",
      "Epoch 347/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1129 - accuracy: 0.8519 - val_loss: 0.1407 - val_accuracy: 0.8127\n",
      "Epoch 348/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1129 - accuracy: 0.8519 - val_loss: 0.1410 - val_accuracy: 0.8119\n",
      "Epoch 349/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1125 - accuracy: 0.8524 - val_loss: 0.1408 - val_accuracy: 0.8124\n",
      "Epoch 350/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1128 - accuracy: 0.8524 - val_loss: 0.1408 - val_accuracy: 0.8129\n",
      "Epoch 351/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1125 - accuracy: 0.8525 - val_loss: 0.1418 - val_accuracy: 0.8107\n",
      "Epoch 352/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1125 - accuracy: 0.8526 - val_loss: 0.1417 - val_accuracy: 0.8105\n",
      "Epoch 353/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1123 - accuracy: 0.8530 - val_loss: 0.1406 - val_accuracy: 0.8136\n",
      "Epoch 354/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1124 - accuracy: 0.8526 - val_loss: 0.1413 - val_accuracy: 0.8104\n",
      "Epoch 355/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1124 - accuracy: 0.8529 - val_loss: 0.1407 - val_accuracy: 0.8121\n",
      "Epoch 356/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1123 - accuracy: 0.8529 - val_loss: 0.1410 - val_accuracy: 0.8121\n",
      "Epoch 357/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1121 - accuracy: 0.8536 - val_loss: 0.1405 - val_accuracy: 0.8129\n",
      "Epoch 358/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1120 - accuracy: 0.8531 - val_loss: 0.1414 - val_accuracy: 0.8124\n",
      "Epoch 359/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1121 - accuracy: 0.8537 - val_loss: 0.1418 - val_accuracy: 0.8097\n",
      "Epoch 360/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1121 - accuracy: 0.8534 - val_loss: 0.1420 - val_accuracy: 0.8113\n",
      "Epoch 361/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1120 - accuracy: 0.8531 - val_loss: 0.1409 - val_accuracy: 0.8112\n",
      "Epoch 362/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1118 - accuracy: 0.8540 - val_loss: 0.1408 - val_accuracy: 0.8130\n",
      "Epoch 363/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1118 - accuracy: 0.8540 - val_loss: 0.1404 - val_accuracy: 0.8135\n",
      "Epoch 364/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1119 - accuracy: 0.8536 - val_loss: 0.1411 - val_accuracy: 0.8137\n",
      "Epoch 365/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1115 - accuracy: 0.8545 - val_loss: 0.1411 - val_accuracy: 0.8123\n",
      "Epoch 366/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1117 - accuracy: 0.8542 - val_loss: 0.1418 - val_accuracy: 0.8101\n",
      "Epoch 367/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1118 - accuracy: 0.8540 - val_loss: 0.1416 - val_accuracy: 0.8119\n",
      "Epoch 368/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1116 - accuracy: 0.8542 - val_loss: 0.1424 - val_accuracy: 0.8113\n",
      "Epoch 369/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1117 - accuracy: 0.8540 - val_loss: 0.1404 - val_accuracy: 0.8131\n",
      "Epoch 370/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1113 - accuracy: 0.8544 - val_loss: 0.1407 - val_accuracy: 0.8134\n",
      "Epoch 371/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1115 - accuracy: 0.8545 - val_loss: 0.1418 - val_accuracy: 0.8117\n",
      "Epoch 372/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1112 - accuracy: 0.8550 - val_loss: 0.1411 - val_accuracy: 0.8137\n",
      "Epoch 373/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1114 - accuracy: 0.8547 - val_loss: 0.1411 - val_accuracy: 0.8131\n",
      "Epoch 374/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1112 - accuracy: 0.8548 - val_loss: 0.1401 - val_accuracy: 0.8152\n",
      "Epoch 375/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1112 - accuracy: 0.8550 - val_loss: 0.1408 - val_accuracy: 0.8122\n",
      "Epoch 376/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1111 - accuracy: 0.8552 - val_loss: 0.1405 - val_accuracy: 0.8137\n",
      "Epoch 377/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1113 - accuracy: 0.8544 - val_loss: 0.1410 - val_accuracy: 0.8122\n",
      "Epoch 378/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1109 - accuracy: 0.8550 - val_loss: 0.1405 - val_accuracy: 0.8143\n",
      "Epoch 379/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1108 - accuracy: 0.8557 - val_loss: 0.1417 - val_accuracy: 0.8112\n",
      "Epoch 380/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1109 - accuracy: 0.8557 - val_loss: 0.1405 - val_accuracy: 0.8132\n",
      "Epoch 381/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1108 - accuracy: 0.8558 - val_loss: 0.1402 - val_accuracy: 0.8146\n",
      "Epoch 382/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1107 - accuracy: 0.8556 - val_loss: 0.1407 - val_accuracy: 0.8131\n",
      "Epoch 383/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1106 - accuracy: 0.8555 - val_loss: 0.1431 - val_accuracy: 0.8092\n",
      "Epoch 384/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1106 - accuracy: 0.8558 - val_loss: 0.1416 - val_accuracy: 0.8120\n",
      "Epoch 385/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1107 - accuracy: 0.8558 - val_loss: 0.1415 - val_accuracy: 0.8107\n",
      "Epoch 386/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1106 - accuracy: 0.8558 - val_loss: 0.1414 - val_accuracy: 0.8129\n",
      "Epoch 387/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1104 - accuracy: 0.8562 - val_loss: 0.1421 - val_accuracy: 0.8109\n",
      "Epoch 388/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1105 - accuracy: 0.8562 - val_loss: 0.1407 - val_accuracy: 0.8142\n",
      "Epoch 389/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1105 - accuracy: 0.8565 - val_loss: 0.1421 - val_accuracy: 0.8099\n",
      "Epoch 390/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1103 - accuracy: 0.8566 - val_loss: 0.1413 - val_accuracy: 0.8127\n",
      "Epoch 391/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1104 - accuracy: 0.8560 - val_loss: 0.1413 - val_accuracy: 0.8134\n",
      "Epoch 392/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1104 - accuracy: 0.8566 - val_loss: 0.1424 - val_accuracy: 0.8103\n",
      "Epoch 393/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1103 - accuracy: 0.8563 - val_loss: 0.1422 - val_accuracy: 0.8115\n",
      "Epoch 394/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1102 - accuracy: 0.8568 - val_loss: 0.1409 - val_accuracy: 0.8146\n",
      "Epoch 395/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1101 - accuracy: 0.8568 - val_loss: 0.1408 - val_accuracy: 0.8132\n",
      "Epoch 396/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1099 - accuracy: 0.8572 - val_loss: 0.1416 - val_accuracy: 0.8124\n",
      "Epoch 397/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1101 - accuracy: 0.8571 - val_loss: 0.1409 - val_accuracy: 0.8136\n",
      "Epoch 398/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1099 - accuracy: 0.8570 - val_loss: 0.1409 - val_accuracy: 0.8130\n",
      "Epoch 399/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1099 - accuracy: 0.8572 - val_loss: 0.1408 - val_accuracy: 0.8155\n",
      "Epoch 400/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1102 - accuracy: 0.8568 - val_loss: 0.1415 - val_accuracy: 0.8125\n",
      "Epoch 401/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1099 - accuracy: 0.8571 - val_loss: 0.1416 - val_accuracy: 0.8114\n",
      "Epoch 402/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1099 - accuracy: 0.8573 - val_loss: 0.1409 - val_accuracy: 0.8147\n",
      "Epoch 403/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1097 - accuracy: 0.8576 - val_loss: 0.1404 - val_accuracy: 0.8156\n",
      "Epoch 404/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1096 - accuracy: 0.8575 - val_loss: 0.1421 - val_accuracy: 0.8109\n",
      "Epoch 405/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1096 - accuracy: 0.8579 - val_loss: 0.1409 - val_accuracy: 0.8138\n",
      "Epoch 406/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1096 - accuracy: 0.8578 - val_loss: 0.1419 - val_accuracy: 0.8132\n",
      "Epoch 407/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1097 - accuracy: 0.8577 - val_loss: 0.1407 - val_accuracy: 0.8143\n",
      "Epoch 408/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1097 - accuracy: 0.8572 - val_loss: 0.1406 - val_accuracy: 0.8141\n",
      "Epoch 409/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1096 - accuracy: 0.8575 - val_loss: 0.1412 - val_accuracy: 0.8130\n",
      "Epoch 410/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1096 - accuracy: 0.8577 - val_loss: 0.1407 - val_accuracy: 0.8143\n",
      "Epoch 411/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1095 - accuracy: 0.8578 - val_loss: 0.1435 - val_accuracy: 0.8107\n",
      "Epoch 412/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1097 - accuracy: 0.8576 - val_loss: 0.1418 - val_accuracy: 0.8133\n",
      "Epoch 413/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1095 - accuracy: 0.8578 - val_loss: 0.1423 - val_accuracy: 0.8121\n",
      "Epoch 414/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1094 - accuracy: 0.8581 - val_loss: 0.1410 - val_accuracy: 0.8137\n",
      "Epoch 415/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1094 - accuracy: 0.8581 - val_loss: 0.1420 - val_accuracy: 0.8124\n",
      "Epoch 416/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1091 - accuracy: 0.8585 - val_loss: 0.1414 - val_accuracy: 0.8135\n",
      "Epoch 417/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1092 - accuracy: 0.8586 - val_loss: 0.1413 - val_accuracy: 0.8135\n",
      "Epoch 418/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1091 - accuracy: 0.8585 - val_loss: 0.1429 - val_accuracy: 0.8112\n",
      "Epoch 419/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1093 - accuracy: 0.8582 - val_loss: 0.1398 - val_accuracy: 0.8173\n",
      "Epoch 420/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1090 - accuracy: 0.8587 - val_loss: 0.1410 - val_accuracy: 0.8139\n",
      "Epoch 421/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1090 - accuracy: 0.8589 - val_loss: 0.1417 - val_accuracy: 0.8111\n",
      "Epoch 422/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1090 - accuracy: 0.8589 - val_loss: 0.1404 - val_accuracy: 0.8164\n",
      "Epoch 423/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1089 - accuracy: 0.8589 - val_loss: 0.1408 - val_accuracy: 0.8155\n",
      "Epoch 424/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1087 - accuracy: 0.8593 - val_loss: 0.1410 - val_accuracy: 0.8148\n",
      "Epoch 425/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1089 - accuracy: 0.8589 - val_loss: 0.1416 - val_accuracy: 0.8132\n",
      "Epoch 426/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1090 - accuracy: 0.8588 - val_loss: 0.1408 - val_accuracy: 0.8149\n",
      "Epoch 427/500\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1088 - accuracy: 0.8590 - val_loss: 0.1410 - val_accuracy: 0.8143\n",
      "Epoch 428/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1086 - accuracy: 0.8593 - val_loss: 0.1405 - val_accuracy: 0.8161\n",
      "Epoch 429/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1088 - accuracy: 0.8591 - val_loss: 0.1416 - val_accuracy: 0.8120\n",
      "Epoch 430/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1086 - accuracy: 0.8594 - val_loss: 0.1401 - val_accuracy: 0.8164\n",
      "Epoch 431/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1085 - accuracy: 0.8598 - val_loss: 0.1404 - val_accuracy: 0.8157\n",
      "Epoch 432/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1084 - accuracy: 0.8596 - val_loss: 0.1409 - val_accuracy: 0.8148\n",
      "Epoch 433/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1084 - accuracy: 0.8597 - val_loss: 0.1413 - val_accuracy: 0.8138\n",
      "Epoch 434/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1086 - accuracy: 0.8593 - val_loss: 0.1411 - val_accuracy: 0.8154\n",
      "Epoch 435/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1085 - accuracy: 0.8597 - val_loss: 0.1422 - val_accuracy: 0.8116\n",
      "Epoch 436/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1086 - accuracy: 0.8594 - val_loss: 0.1422 - val_accuracy: 0.8130\n",
      "Epoch 437/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1083 - accuracy: 0.8600 - val_loss: 0.1417 - val_accuracy: 0.8131\n",
      "Epoch 438/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1082 - accuracy: 0.8596 - val_loss: 0.1407 - val_accuracy: 0.8164\n",
      "Epoch 439/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1082 - accuracy: 0.8602 - val_loss: 0.1412 - val_accuracy: 0.8156\n",
      "Epoch 440/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1083 - accuracy: 0.8601 - val_loss: 0.1425 - val_accuracy: 0.8117\n",
      "Epoch 441/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1084 - accuracy: 0.8598 - val_loss: 0.1410 - val_accuracy: 0.8148\n",
      "Epoch 442/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1083 - accuracy: 0.8599 - val_loss: 0.1406 - val_accuracy: 0.8159\n",
      "Epoch 443/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1083 - accuracy: 0.8597 - val_loss: 0.1404 - val_accuracy: 0.8161\n",
      "Epoch 444/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1081 - accuracy: 0.8600 - val_loss: 0.1409 - val_accuracy: 0.8152\n",
      "Epoch 445/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1082 - accuracy: 0.8599 - val_loss: 0.1415 - val_accuracy: 0.8117\n",
      "Epoch 446/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1080 - accuracy: 0.8605 - val_loss: 0.1407 - val_accuracy: 0.8159\n",
      "Epoch 447/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1082 - accuracy: 0.8602 - val_loss: 0.1409 - val_accuracy: 0.8158\n",
      "Epoch 448/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1081 - accuracy: 0.8603 - val_loss: 0.1412 - val_accuracy: 0.8161\n",
      "Epoch 449/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1081 - accuracy: 0.8602 - val_loss: 0.1438 - val_accuracy: 0.8091\n",
      "Epoch 450/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1079 - accuracy: 0.8609 - val_loss: 0.1404 - val_accuracy: 0.8156\n",
      "Epoch 451/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1082 - accuracy: 0.8600 - val_loss: 0.1397 - val_accuracy: 0.8172\n",
      "Epoch 452/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1079 - accuracy: 0.8608 - val_loss: 0.1396 - val_accuracy: 0.8182\n",
      "Epoch 453/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1082 - accuracy: 0.8600 - val_loss: 0.1413 - val_accuracy: 0.8151\n",
      "Epoch 454/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1079 - accuracy: 0.8605 - val_loss: 0.1402 - val_accuracy: 0.8161\n",
      "Epoch 455/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1078 - accuracy: 0.8611 - val_loss: 0.1424 - val_accuracy: 0.8125\n",
      "Epoch 456/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1077 - accuracy: 0.8609 - val_loss: 0.1416 - val_accuracy: 0.8141\n",
      "Epoch 457/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1077 - accuracy: 0.8605 - val_loss: 0.1419 - val_accuracy: 0.8144\n",
      "Epoch 458/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1074 - accuracy: 0.8614 - val_loss: 0.1404 - val_accuracy: 0.8155\n",
      "Epoch 459/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1078 - accuracy: 0.8609 - val_loss: 0.1414 - val_accuracy: 0.8147\n",
      "Epoch 460/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1077 - accuracy: 0.8610 - val_loss: 0.1413 - val_accuracy: 0.8147\n",
      "Epoch 461/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1076 - accuracy: 0.8609 - val_loss: 0.1422 - val_accuracy: 0.8126\n",
      "Epoch 462/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1077 - accuracy: 0.8609 - val_loss: 0.1410 - val_accuracy: 0.8152\n",
      "Epoch 463/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1073 - accuracy: 0.8617 - val_loss: 0.1411 - val_accuracy: 0.8155\n",
      "Epoch 464/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1074 - accuracy: 0.8615 - val_loss: 0.1411 - val_accuracy: 0.8150\n",
      "Epoch 465/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1075 - accuracy: 0.8614 - val_loss: 0.1403 - val_accuracy: 0.8166\n",
      "Epoch 466/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1074 - accuracy: 0.8616 - val_loss: 0.1406 - val_accuracy: 0.8160\n",
      "Epoch 467/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1073 - accuracy: 0.8618 - val_loss: 0.1431 - val_accuracy: 0.8114\n",
      "Epoch 468/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1074 - accuracy: 0.8613 - val_loss: 0.1402 - val_accuracy: 0.8161\n",
      "Epoch 469/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1073 - accuracy: 0.8617 - val_loss: 0.1410 - val_accuracy: 0.8152\n",
      "Epoch 470/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1072 - accuracy: 0.8619 - val_loss: 0.1398 - val_accuracy: 0.8183\n",
      "Epoch 471/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1073 - accuracy: 0.8619 - val_loss: 0.1408 - val_accuracy: 0.8173\n",
      "Epoch 472/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1071 - accuracy: 0.8621 - val_loss: 0.1414 - val_accuracy: 0.8159\n",
      "Epoch 473/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1072 - accuracy: 0.8621 - val_loss: 0.1430 - val_accuracy: 0.8126\n",
      "Epoch 474/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1073 - accuracy: 0.8619 - val_loss: 0.1425 - val_accuracy: 0.8124\n",
      "Epoch 475/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1071 - accuracy: 0.8621 - val_loss: 0.1418 - val_accuracy: 0.8132\n",
      "Epoch 476/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1071 - accuracy: 0.8620 - val_loss: 0.1433 - val_accuracy: 0.8122\n",
      "Epoch 477/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1070 - accuracy: 0.8621 - val_loss: 0.1408 - val_accuracy: 0.8163\n",
      "Epoch 478/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1072 - accuracy: 0.8619 - val_loss: 0.1404 - val_accuracy: 0.8172\n",
      "Epoch 479/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1070 - accuracy: 0.8622 - val_loss: 0.1417 - val_accuracy: 0.8138\n",
      "Epoch 480/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1070 - accuracy: 0.8623 - val_loss: 0.1416 - val_accuracy: 0.8158\n",
      "Epoch 481/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1068 - accuracy: 0.8624 - val_loss: 0.1419 - val_accuracy: 0.8140\n",
      "Epoch 482/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1069 - accuracy: 0.8623 - val_loss: 0.1408 - val_accuracy: 0.8156\n",
      "Epoch 483/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1070 - accuracy: 0.8622 - val_loss: 0.1419 - val_accuracy: 0.8142\n",
      "Epoch 484/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1071 - accuracy: 0.8620 - val_loss: 0.1411 - val_accuracy: 0.8149\n",
      "Epoch 485/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1068 - accuracy: 0.8626 - val_loss: 0.1427 - val_accuracy: 0.8130\n",
      "Epoch 486/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1070 - accuracy: 0.8623 - val_loss: 0.1398 - val_accuracy: 0.8179\n",
      "Epoch 487/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1068 - accuracy: 0.8626 - val_loss: 0.1418 - val_accuracy: 0.8146\n",
      "Epoch 488/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1067 - accuracy: 0.8627 - val_loss: 0.1413 - val_accuracy: 0.8157\n",
      "Epoch 489/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1066 - accuracy: 0.8628 - val_loss: 0.1413 - val_accuracy: 0.8161\n",
      "Epoch 490/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1066 - accuracy: 0.8629 - val_loss: 0.1407 - val_accuracy: 0.8174\n",
      "Epoch 491/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1067 - accuracy: 0.8624 - val_loss: 0.1423 - val_accuracy: 0.8134\n",
      "Epoch 492/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1066 - accuracy: 0.8630 - val_loss: 0.1408 - val_accuracy: 0.8160\n",
      "Epoch 493/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1065 - accuracy: 0.8628 - val_loss: 0.1402 - val_accuracy: 0.8163\n",
      "Epoch 494/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1066 - accuracy: 0.8632 - val_loss: 0.1414 - val_accuracy: 0.8155\n",
      "Epoch 495/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1065 - accuracy: 0.8631 - val_loss: 0.1406 - val_accuracy: 0.8159\n",
      "Epoch 496/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1067 - accuracy: 0.8627 - val_loss: 0.1429 - val_accuracy: 0.8125\n",
      "Epoch 497/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1064 - accuracy: 0.8635 - val_loss: 0.1418 - val_accuracy: 0.8141\n",
      "Epoch 498/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1065 - accuracy: 0.8631 - val_loss: 0.1416 - val_accuracy: 0.8152\n",
      "Epoch 499/500\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1063 - accuracy: 0.8632 - val_loss: 0.1422 - val_accuracy: 0.8139\n",
      "Epoch 500/500\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1067 - accuracy: 0.8627 - val_loss: 0.1412 - val_accuracy: 0.8161\n"
     ]
    }
   ],
   "source": [
    "# callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=200, restore_best_weights=True)]\n",
    "test1_model_history = test1_model.fit(X_train,\n",
    "                                      y_train,\n",
    "                                      epochs=500,\n",
    "                                      batch_size=512,\n",
    "                                      validation_data=(X_val,y_val),\n",
    "                                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_model.save(\"new_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x324 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(11,4.5))    \n",
    "\n",
    "results_dict = test1_model_history.history\n",
    "epochs = range(1,len(results_dict['accuracy'])+1)\n",
    "\n",
    "#accuracy\n",
    "acc_values = results_dict['accuracy']\n",
    "val_acc_values = results_dict['val_accuracy']\n",
    "    \n",
    "axs[0].plot(epochs,acc_values,color='black',label='train',linewidth=1.5,linestyle='-')\n",
    "axs[0].plot(epochs,val_acc_values,color='red',label='test',linewidth=1.5,linestyle='-')\n",
    "axs[0].set_xlabel('epochs')\n",
    "minorLocatorX = AutoMinorLocator()\n",
    "axs[0].xaxis.set_minor_locator(minorLocatorX)\n",
    "axs[0].set_ylabel('accuracy')\n",
    "axs[0].set_ylim([0.5, 1.02])   \n",
    "minorLocatorY = AutoMinorLocator()\n",
    "axs[0].yaxis.set_minor_locator(minorLocatorY)\n",
    "axs[0].tick_params(which='major', length=6)\n",
    "axs[0].tick_params(which='minor', length=3, color='black')       \n",
    "axs[0].legend(loc='lower right')\n",
    "    \n",
    "#loss\n",
    "loss_values = results_dict['loss']\n",
    "val_loss_values = results_dict['val_loss']\n",
    "       \n",
    "axs[1].plot(epochs,loss_values,color='black',label='train',linewidth=1.5,linestyle='-')\n",
    "axs[1].plot(epochs,val_loss_values,color='red',label='test',linewidth=1.5,linestyle='-')\n",
    "axs[1].set_xlabel('epochs')\n",
    "minorLocatorX = AutoMinorLocator()\n",
    "axs[1].xaxis.set_minor_locator(minorLocatorX)   \n",
    "axs[1].set_ylabel('loss')\n",
    "axs[1].set_ylim([0.0, 0.2])   \n",
    "minorLocatorY = AutoMinorLocator()\n",
    "axs[1].yaxis.set_minor_locator(minorLocatorY)\n",
    "axs[1].tick_params(which='major', length=6)\n",
    "axs[1].tick_params(which='minor', length=3, color='black')    \n",
    "axs[1].legend(loc='upper right')\n",
    "\n",
    "axs[0].set_title('Training and test accuracy after {} epochs: \\n {:.3f} (train), {:.3f} (validation)'\n",
    "                 .format(len(epochs),acc_values[-1],val_acc_values[-1]));\n",
    "\n",
    "axs[1].set_title('Training and test loss after {} epochs: \\n {:.3f} (train), {:.3f} (validation)'\n",
    "                 .format(len(epochs),loss_values[-1],val_loss_values[-1]));\n",
    "plt.savefig('plots_ann_new.png', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3613/3613 [==============================] - 3s 925us/step\n",
      "Traning and Testing on raw data, all features \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred2 =test1_model.predict(X_test)\n",
    "#####\n",
    "print('Traning and Testing on raw data, all features \\n');\n",
    "#### Model accuracy\n",
    "# print(\"Accuracy:\", metrics.accuracy_score(y_test, ypred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((115600, 1), (115600,))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(ypred2), np.shape(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEURAL NETWORK\n",
      "Accuracy: 0.8130709342560554\n",
      "F1: 0.8160012261475975\n",
      "Precision: 0.8031915785238949\n",
      "AUC: 0.8775074884286338\n"
     ]
    }
   ],
   "source": [
    "print(\"NEURAL NETWORK\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, ypred2.round()))\n",
    "print(\"F1:\", metrics.f1_score(y_test, ypred2.round()))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, ypred2.round()))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, ypred2)\n",
    "print(\"AUC:\", metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[46075 11741]\n",
      " [ 9868 47916]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test, ypred2.round(), classes=['not in halo', 'in halo'])\n",
    "plt.title(\"NEURAL NETWORK\")\n",
    "plt.savefig(\"conf_matrix_ann_new.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
